#!/usr/bin/env python3
"""
TechCrunchçˆ¬å–é—®é¢˜å’Œå›¾ç‰‡åˆ é™¤é—®é¢˜è¯Šæ–­è„šæœ¬
"""

import sys
import os
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_techcrunch_crawler():
    """æµ‹è¯•TechCrunchçˆ¬è™«"""
    print("ğŸ§ª æµ‹è¯•TechCrunchçˆ¬è™«")
    print("="*50)
    
    try:
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        backend_path = os.path.join(os.path.dirname(__file__), 'backend')
        sys.path.insert(0, backend_path)
        
        # è®¾ç½®Djangoç¯å¢ƒ
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'alpha.settings')
        
        import django
        django.setup()
        
        from apps.english.news_crawler import TechCrunchNewsCrawler
        
        print("1. åˆ›å»ºTechCrunchçˆ¬è™«å®ä¾‹...")
        crawler = TechCrunchNewsCrawler()
        print("âœ… TechCrunchçˆ¬è™«åˆ›å»ºæˆåŠŸ")
        
        print("2. æ£€æŸ¥RSSæº...")
        print(f"RSSæºæ•°é‡: {len(crawler.rss_feeds)}")
        for i, rss_url in enumerate(crawler.rss_feeds, 1):
            print(f"   {i}. {rss_url}")
        
        print("3. æµ‹è¯•RSSå†…å®¹è·å–...")
        for rss_url in crawler.rss_feeds:
            print(f"   æµ‹è¯•: {rss_url}")
            try:
                soup = crawler.get_rss_content(rss_url)
                if soup:
                    items = soup.find_all('item')
                    print(f"   âœ… æˆåŠŸè·å– {len(items)} ä¸ªRSSæ¡ç›®")
                    
                    if items:
                        # æµ‹è¯•ç¬¬ä¸€ä¸ªæ¡ç›®
                        first_item = items[0]
                        title_elem = first_item.find('title')
                        link_elem = first_item.find('link')
                        
                        if title_elem and link_elem:
                            title = crawler.clean_text(title_elem.get_text())
                            url = link_elem.get_text().strip()
                            print(f"   ç¤ºä¾‹æ ‡é¢˜: {title[:50]}...")
                            print(f"   ç¤ºä¾‹URL: {url}")
                            
                            # æµ‹è¯•æ–‡ç« å†…å®¹è·å–
                            print("   æµ‹è¯•æ–‡ç« å†…å®¹è·å–...")
                            article_data = crawler.get_article_content(url)
                            if article_data:
                                content_length = len(article_data['content'])
                                print(f"   âœ… æˆåŠŸè·å–æ–‡ç« å†…å®¹: {content_length} å­—ç¬¦")
                                print(f"   å›¾ç‰‡URL: {article_data.get('image_url', 'æ— ')}")
                            else:
                                print("   âŒ æ— æ³•è·å–æ–‡ç« å†…å®¹")
                        else:
                            print("   âŒ RSSæ¡ç›®æ ¼å¼ä¸æ­£ç¡®")
                else:
                    print("   âŒ æ— æ³•è·å–RSSå†…å®¹")
                    
            except Exception as e:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
        
        print("4. æµ‹è¯•å®Œæ•´çˆ¬å–...")
        news_items = crawler.crawl_news_list()
        print(f"âœ… æˆåŠŸçˆ¬å– {len(news_items)} æ¡TechCrunchæ–°é—»")
        
        if news_items:
            print("5. æ˜¾ç¤ºçˆ¬å–çš„æ–°é—»:")
            for i, news in enumerate(news_items[:3], 1):
                print(f"   {i}. {news.title[:60]}...")
                print(f"      æ¥æº: {news.source}")
                print(f"      éš¾åº¦: {news.difficulty_level}")
                print(f"      å†…å®¹é•¿åº¦: {len(news.content)} å­—ç¬¦")
                print(f"      å›¾ç‰‡: {news.image_url or 'æ— '}")
                print()
        
        return True
        
    except Exception as e:
        print(f"âŒ TechCrunchçˆ¬è™«æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_news_deletion_with_image_cleanup():
    """æµ‹è¯•æ–°é—»åˆ é™¤æ—¶çš„å›¾ç‰‡æ¸…ç†"""
    print("\nğŸ§ª æµ‹è¯•æ–°é—»åˆ é™¤æ—¶çš„å›¾ç‰‡æ¸…ç†")
    print("="*50)
    
    try:
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        backend_path = os.path.join(os.path.dirname(__file__), 'backend')
        sys.path.insert(0, backend_path)
        
        # è®¾ç½®Djangoç¯å¢ƒ
        os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'alpha.settings')
        
        import django
        django.setup()
        
        from apps.english.models import News
        from django.conf import settings
        import os
        
        print("1. æ£€æŸ¥ç°æœ‰æ–°é—»çš„å›¾ç‰‡...")
        news_with_images = News.objects.filter(image_url__startswith='news_images/')
        print(f"   æœ‰æœ¬åœ°å›¾ç‰‡çš„æ–°é—»æ•°é‡: {news_with_images.count()}")
        
        if news_with_images.exists():
            print("2. æ˜¾ç¤ºæœ‰æœ¬åœ°å›¾ç‰‡çš„æ–°é—»:")
            for news in news_with_images[:3]:
                print(f"   - {news.title[:50]}...")
                print(f"     å›¾ç‰‡è·¯å¾„: {news.image_url}")
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                if news.image_url.startswith('news_images/'):
                    image_path = os.path.join(settings.MEDIA_ROOT, news.image_url)
                    if os.path.exists(image_path):
                        file_size = os.path.getsize(image_path)
                        print(f"     æ–‡ä»¶å­˜åœ¨ï¼Œå¤§å°: {file_size} å­—èŠ‚")
                    else:
                        print(f"     æ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
                print()
        
        print("3. æµ‹è¯•æ–°é—»åˆ é™¤åŠŸèƒ½...")
        # åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ–°é—»ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        test_news = News.objects.filter(image_url__startswith='news_images/').first()
        
        if test_news:
            print(f"   æµ‹è¯•åˆ é™¤æ–°é—»: {test_news.title[:50]}...")
            print(f"   å›¾ç‰‡è·¯å¾„: {test_news.image_url}")
            
            # æ£€æŸ¥åˆ é™¤å‰çš„å›¾ç‰‡æ–‡ä»¶
            if test_news.image_url.startswith('news_images/'):
                image_path = os.path.join(settings.MEDIA_ROOT, test_news.image_url)
                if os.path.exists(image_path):
                    print(f"   åˆ é™¤å‰å›¾ç‰‡æ–‡ä»¶å­˜åœ¨: {image_path}")
                    
                    # è®°å½•æ–‡ä»¶ä¿¡æ¯
                    file_size = os.path.getsize(image_path)
                    print(f"   æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
                    
                    # åˆ é™¤æ–°é—»
                    news_id = test_news.id
                    test_news.delete()
                    
                    # æ£€æŸ¥åˆ é™¤åçš„å›¾ç‰‡æ–‡ä»¶
                    if os.path.exists(image_path):
                        print("   âŒ æ–°é—»åˆ é™¤åå›¾ç‰‡æ–‡ä»¶ä»ç„¶å­˜åœ¨")
                        print("   âš ï¸ éœ€è¦å®ç°å›¾ç‰‡æ–‡ä»¶æ¸…ç†åŠŸèƒ½")
                    else:
                        print("   âœ… æ–°é—»åˆ é™¤åå›¾ç‰‡æ–‡ä»¶å·²æ¸…ç†")
                else:
                    print("   âš ï¸ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•æµ‹è¯•æ¸…ç†åŠŸèƒ½")
            else:
                print("   âš ï¸ ä¸æ˜¯æœ¬åœ°å›¾ç‰‡ï¼Œè·³è¿‡æ¸…ç†æµ‹è¯•")
        else:
            print("   âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœ‰æœ¬åœ°å›¾ç‰‡çš„æ–°é—»ç”¨äºæµ‹è¯•")
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾ç‰‡æ¸…ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def create_image_cleanup_solution():
    """åˆ›å»ºå›¾ç‰‡æ¸…ç†è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ”§ å›¾ç‰‡æ¸…ç†è§£å†³æ–¹æ¡ˆ")
    print("="*50)
    
    print("é—®é¢˜åˆ†æ:")
    print("1. Newsæ¨¡å‹æ²¡æœ‰é‡å†™deleteæ–¹æ³•")
    print("2. åˆ é™¤æ–°é—»æ—¶ä¸ä¼šè‡ªåŠ¨æ¸…ç†æœ¬åœ°å›¾ç‰‡æ–‡ä»¶")
    print("3. éœ€è¦å®ç°å›¾ç‰‡æ–‡ä»¶æ¸…ç†åŠŸèƒ½")
    
    print("\nè§£å†³æ–¹æ¡ˆ:")
    print("1. é‡å†™Newsæ¨¡å‹çš„deleteæ–¹æ³•")
    print("2. åœ¨åˆ é™¤æ–°é—»æ—¶æ£€æŸ¥å¹¶åˆ é™¤æœ¬åœ°å›¾ç‰‡æ–‡ä»¶")
    print("3. æ·»åŠ å›¾ç‰‡æ–‡ä»¶æ¸…ç†çš„å•å…ƒæµ‹è¯•")
    
    print("\nå®ç°æ­¥éª¤:")
    print("1. ä¿®æ”¹Newsæ¨¡å‹ï¼Œæ·»åŠ deleteæ–¹æ³•")
    print("2. åˆ›å»ºå›¾ç‰‡æ–‡ä»¶æ¸…ç†å‡½æ•°")
    print("3. æ·»åŠ å•å…ƒæµ‹è¯•éªŒè¯åŠŸèƒ½")
    print("4. æ›´æ–°æ–‡æ¡£è¯´æ˜")

def create_techcrunch_fix_solution():
    """åˆ›å»ºTechCrunchä¿®å¤è§£å†³æ–¹æ¡ˆ"""
    print("\nğŸ”§ TechCrunchä¿®å¤è§£å†³æ–¹æ¡ˆ")
    print("="*50)
    
    print("é—®é¢˜åˆ†æ:")
    print("1. TechCrunch RSSæºå¯èƒ½ä¸å¯è®¿é—®")
    print("2. æ–‡ç« å†…å®¹æå–å¯èƒ½å¤±è´¥")
    print("3. åçˆ¬è™«æœºåˆ¶å¯èƒ½é˜»æ­¢è®¿é—®")
    
    print("\nè§£å†³æ–¹æ¡ˆ:")
    print("1. æ›´æ–°RSSæºURL")
    print("2. æ”¹è¿›å†…å®¹æå–é€»è¾‘")
    print("3. æ·»åŠ æ›´å¤šé”™è¯¯å¤„ç†")
    print("4. ä½¿ç”¨å¤‡ç”¨RSSæº")
    
    print("\nå®ç°æ­¥éª¤:")
    print("1. æµ‹è¯•å’Œæ›´æ–°RSSæº")
    print("2. æ”¹è¿›TechCrunchNewsCrawler")
    print("3. æ·»åŠ é‡è¯•æœºåˆ¶")
    print("4. åˆ›å»ºå•å…ƒæµ‹è¯•")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª TechCrunchçˆ¬å–å’Œå›¾ç‰‡æ¸…ç†é—®é¢˜è¯Šæ–­")
    print("="*60)
    
    # æµ‹è¯•TechCrunchçˆ¬è™«
    techcrunch_ok = test_techcrunch_crawler()
    
    # æµ‹è¯•å›¾ç‰‡æ¸…ç†
    image_cleanup_ok = test_news_deletion_with_image_cleanup()
    
    # ç”Ÿæˆè§£å†³æ–¹æ¡ˆ
    create_techcrunch_fix_solution()
    create_image_cleanup_solution()
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
    print("="*60)
    
    print(f"TechCrunchçˆ¬è™«: {'âœ… æ­£å¸¸' if techcrunch_ok else 'âŒ æœ‰é—®é¢˜'}")
    print(f"å›¾ç‰‡æ¸…ç†åŠŸèƒ½: {'âœ… æ­£å¸¸' if image_cleanup_ok else 'âŒ æœ‰é—®é¢˜'}")
    
    print("\nğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
    print("1. ä¿®å¤TechCrunchçˆ¬è™«é—®é¢˜")
    print("2. å®ç°å›¾ç‰‡æ–‡ä»¶æ¸…ç†åŠŸèƒ½")
    print("3. åˆ›å»ºç›¸åº”çš„å•å…ƒæµ‹è¯•")
    print("4. éªŒè¯ä¿®å¤æ•ˆæœ")

if __name__ == "__main__":
    main()




