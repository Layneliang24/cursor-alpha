# AIé›†æˆæŒ‡å—ï¼šå¦‚ä½•åœ¨å¼€å‘æµç¨‹ä¸­å¼•å…¥AI

## æ¦‚è¿°

æœ¬æŒ‡å—å±•ç¤ºå¦‚ä½•åœ¨ç°æœ‰çš„`req_to_test_pipeline.py`æµæ°´çº¿ä¸­é›†æˆAIåŠŸèƒ½ï¼Œè®©AIè‡ªåŠ¨å®Œæˆæµ‹è¯•æ–‡ä»¶ç”Ÿæˆã€ä»£ç å®ç°ç­‰ä»»åŠ¡ã€‚

## å½“å‰ç³»ç»Ÿæ¶æ„

ç°æœ‰ç³»ç»ŸåŒ…å«ï¼š
- `req_to_test_pipeline.py` - éœ€æ±‚åˆ°æµ‹è¯•çš„è‡ªåŠ¨åŒ–æµæ°´çº¿
- `requirement_template.md` - æ ‡å‡†åŒ–éœ€æ±‚æ¨¡æ¿
- `TestGenerator` - æµ‹è¯•ä»£ç ç”Ÿæˆå™¨
- `CodeGenerator` - åŸºç¡€ä»£ç æ¡†æ¶ç”Ÿæˆå™¨

## AIé›†æˆæ–¹æ¡ˆ

### 1. AIé…ç½®ç®¡ç†

åˆ›å»ºAIé…ç½®æ–‡ä»¶ `ai_config.json`ï¼š

```json
{
  "providers": {
    "openai": {
      "api_key": "your-openai-api-key",
      "base_url": "https://api.openai.com/v1",
      "model": "gpt-4",
      "max_tokens": 4000
    },
    "claude": {
      "api_key": "your-claude-api-key",
      "base_url": "https://api.anthropic.com",
      "model": "claude-3-sonnet-20240229",
      "max_tokens": 4000
    },
    "ollama": {
      "base_url": "http://localhost:11434",
      "model": "codellama:13b",
      "max_tokens": 4000
    },
    "mock": {
      "enabled": true,
      "response_template": "# AIç”Ÿæˆçš„ä»£ç \n# è¿™æ˜¯æ¨¡æ‹Ÿæ¨¡å¼ï¼Œå®é™…ä½¿ç”¨æ—¶ä¼šè°ƒç”¨çœŸå®AI"
    }
  },
  "default_provider": "mock",
  "prompts": {
    "test_generation": "åŸºäºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•ä»£ç ï¼š\n{requirement}\n\nè¯·ç”ŸæˆåŒ…å«å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•çš„å®Œæ•´ä»£ç ã€‚",
    "code_implementation": "åŸºäºä»¥ä¸‹éœ€æ±‚å’Œæµ‹è¯•ç”¨ä¾‹å®ç°å®Œæ•´çš„åŠŸèƒ½ä»£ç ï¼š\néœ€æ±‚ï¼š{requirement}\næµ‹è¯•ï¼š{tests}\n\nè¯·å®ç°æ‰€æœ‰å¿…è¦çš„æ¨¡å‹ã€è§†å›¾ã€åºåˆ—åŒ–å™¨ç­‰ã€‚",
    "code_review": "è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç å¹¶æä¾›æ”¹è¿›å»ºè®®ï¼š\n{code}\n\né‡ç‚¹å…³æ³¨ä»£ç è´¨é‡ã€å®‰å…¨æ€§å’Œæ€§èƒ½ã€‚"
  }
}
```

### 2. AIæ¥å£ç®¡ç†å™¨

åˆ›å»º `ai_interface.py`ï¼š

```python
import json
import requests
from typing import Dict, Any, Optional
from pathlib import Path

class AIInterface:
    """AIæ¥å£ç®¡ç†å™¨"""
    
    def __init__(self, config_path: str = "ai_config.json"):
        self.config = self._load_config(config_path)
        self.provider = self.config.get("default_provider", "mock")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½AIé…ç½®"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return self._create_default_config(config_path)
    
    def _create_default_config(self, config_path: str) -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶"""
        default_config = {
            "providers": {
                "mock": {"enabled": True}
            },
            "default_provider": "mock"
        }
        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, indent=2, ensure_ascii=False)
        return default_config
    
    def generate_code(self, prompt: str, context: Dict[str, Any] = None) -> str:
        """ç”Ÿæˆä»£ç """
        if self.provider == "mock":
            return self._mock_generate(prompt)
        elif self.provider == "openai":
            return self._openai_generate(prompt)
        elif self.provider == "claude":
            return self._claude_generate(prompt)
        elif self.provider == "ollama":
            return self._ollama_generate(prompt)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„AIæä¾›å•†: {self.provider}")
    
    def _mock_generate(self, prompt: str) -> str:
        """æ¨¡æ‹ŸAIç”Ÿæˆï¼ˆç”¨äºæ¼”ç¤ºï¼‰"""
        return f"""# AIç”Ÿæˆçš„ä»£ç ï¼ˆæ¨¡æ‹Ÿæ¨¡å¼ï¼‰
# æç¤ºè¯: {prompt[:100]}...

# è¿™æ˜¯æ¨¡æ‹Ÿç”Ÿæˆçš„ä»£ç 
# å®é™…ä½¿ç”¨æ—¶ä¼šè°ƒç”¨çœŸå®çš„AI API

def generated_function():
    pass
"""
    
    def _openai_generate(self, prompt: str) -> str:
        """OpenAI APIè°ƒç”¨"""
        config = self.config["providers"]["openai"]
        headers = {
            "Authorization": f"Bearer {config['api_key']}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": config["model"],
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "max_tokens": config["max_tokens"]
        }
        
        response = requests.post(
            f"{config['base_url']}/chat/completions",
            headers=headers,
            json=data
        )
        
        if response.status_code == 200:
            return response.json()["choices"][0]["message"]["content"]
        else:
            raise Exception(f"OpenAI APIè°ƒç”¨å¤±è´¥: {response.text}")
    
    def _claude_generate(self, prompt: str) -> str:
        """Claude APIè°ƒç”¨"""
        # ç±»ä¼¼OpenAIçš„å®ç°
        pass
    
    def _ollama_generate(self, prompt: str) -> str:
        """Ollamaæœ¬åœ°æ¨¡å‹è°ƒç”¨"""
        config = self.config["providers"]["ollama"]
        data = {
            "model": config["model"],
            "prompt": prompt,
            "stream": False
        }
        
        response = requests.post(
            f"{config['base_url']}/api/generate",
            json=data
        )
        
        if response.status_code == 200:
            return response.json()["response"]
        else:
            raise Exception(f"Ollama APIè°ƒç”¨å¤±è´¥: {response.text}")
```

### 3. å¢å¼ºçš„æµæ°´çº¿ç®¡ç†å™¨

ä¿®æ”¹ `req_to_test_pipeline.py`ï¼Œæ·»åŠ AIå¢å¼ºåŠŸèƒ½ï¼š

```python
# åœ¨ç°æœ‰çš„PipelineManagerç±»ä¸­æ·»åŠ AIåŠŸèƒ½

class AIEnhancedPipelineManager(PipelineManager):
    """AIå¢å¼ºçš„æµæ°´çº¿ç®¡ç†å™¨"""
    
    def __init__(self, project_root: str, ai_enabled: bool = False):
        super().__init__(project_root)
        self.ai_enabled = ai_enabled
        if ai_enabled:
            self.ai_interface = AIInterface()
    
    def run_ai_pipeline(self, requirement_input: str, 
                       input_type: str = 'file',
                       ai_tasks: List[str] = None) -> Dict:
        """è¿è¡ŒAIå¢å¼ºçš„æµæ°´çº¿"""
        
        if ai_tasks is None:
            ai_tasks = ['generate_tests', 'implement_code', 'review_code']
        
        # å…ˆè¿è¡ŒåŸºç¡€æµæ°´çº¿
        result = self.run_pipeline(
            requirement_input, input_type,
            create_branch=True,
            generate_tests=False,  # AIä¼šé‡æ–°ç”Ÿæˆ
            generate_code=False,   # AIä¼šé‡æ–°ç”Ÿæˆ
            create_issue=True,
            commit_changes=False   # æœ€åç»Ÿä¸€æäº¤
        )
        
        if not result['success']:
            return result
        
        req = result['requirement']
        ai_results = {}
        
        # AIç”Ÿæˆæµ‹è¯•
        if 'generate_tests' in ai_tasks:
            ai_results['tests'] = self._ai_generate_tests(req)
        
        # AIå®ç°ä»£ç 
        if 'implement_code' in ai_tasks:
            ai_results['code'] = self._ai_implement_code(req, ai_results.get('tests'))
        
        # AIä»£ç å®¡æŸ¥
        if 'review_code' in ai_tasks:
            ai_results['review'] = self._ai_review_code(ai_results.get('code'))
        
        # åº”ç”¨AIç”Ÿæˆçš„å†…å®¹
        self._apply_ai_results(req, ai_results)
        
        # æäº¤æ‰€æœ‰æ›´æ”¹
        if ai_results:
            commit_msg = f"AIå®ç°: {req.title}\n\n" + "\n".join([
                f"- {task}: å·²å®Œæˆ" for task in ai_tasks
            ])
            self.git_manager.commit_changes(req, commit_msg)
        
        result['ai_results'] = ai_results
        return result
    
    def _ai_generate_tests(self, req: Requirement) -> Dict[str, str]:
        """AIç”Ÿæˆæµ‹è¯•ä»£ç """
        prompt_template = self.ai_interface.config.get('prompts', {}).get(
            'test_generation', 
            'åŸºäºä»¥ä¸‹éœ€æ±‚ç”Ÿæˆå®Œæ•´çš„æµ‹è¯•ä»£ç ï¼š\n{requirement}'
        )
        
        prompt = prompt_template.format(
            requirement=f"æ ‡é¢˜: {req.title}\næè¿°: {req.description}\néªŒæ”¶æ ‡å‡†: {req.acceptance_criteria}"
        )
        
        test_code = self.ai_interface.generate_code(prompt)
        
        # ä¿å­˜æµ‹è¯•æ–‡ä»¶
        test_files = {
            'unit_test': test_code,
            'integration_test': test_code,  # å¯ä»¥åˆ†åˆ«ç”Ÿæˆ
            'e2e_test': test_code
        }
        
        return test_files
    
    def _ai_implement_code(self, req: Requirement, tests: Dict[str, str] = None) -> Dict[str, str]:
        """AIå®ç°åŠŸèƒ½ä»£ç """
        prompt_template = self.ai_interface.config.get('prompts', {}).get(
            'code_implementation',
            'åŸºäºä»¥ä¸‹éœ€æ±‚å®ç°å®Œæ•´çš„åŠŸèƒ½ä»£ç ï¼š\néœ€æ±‚ï¼š{requirement}\næµ‹è¯•ï¼š{tests}'
        )
        
        tests_content = "\n\n".join(tests.values()) if tests else "æ— æµ‹è¯•ç”¨ä¾‹"
        
        prompt = prompt_template.format(
            requirement=f"æ ‡é¢˜: {req.title}\næè¿°: {req.description}",
            tests=tests_content
        )
        
        code = self.ai_interface.generate_code(prompt)
        
        # æ ¹æ®ç»„ä»¶ç±»å‹åˆ†åˆ«ç”Ÿæˆä»£ç 
        code_files = {}
        for component in req.components:
            if component == 'backend':
                code_files['models'] = code
                code_files['views'] = code
                code_files['serializers'] = code
            elif component == 'frontend':
                code_files['components'] = code
                code_files['services'] = code
        
        return code_files
    
    def _ai_review_code(self, code: Dict[str, str]) -> str:
        """AIä»£ç å®¡æŸ¥"""
        if not code:
            return "æ— ä»£ç éœ€è¦å®¡æŸ¥"
        
        prompt_template = self.ai_interface.config.get('prompts', {}).get(
            'code_review',
            'è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç å¹¶æä¾›æ”¹è¿›å»ºè®®ï¼š\n{code}'
        )
        
        all_code = "\n\n".join(code.values())
        prompt = prompt_template.format(code=all_code)
        
        return self.ai_interface.generate_code(prompt)
    
    def _apply_ai_results(self, req: Requirement, ai_results: Dict[str, Any]):
        """åº”ç”¨AIç”Ÿæˆçš„ç»“æœåˆ°æ–‡ä»¶ç³»ç»Ÿ"""
        # åˆ›å»ºç›®å½•ç»“æ„
        req_dir = self.project_root / 'ai_generated' / req.id
        req_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æµ‹è¯•æ–‡ä»¶
        if 'tests' in ai_results:
            tests_dir = req_dir / 'tests'
            tests_dir.mkdir(exist_ok=True)
            for test_type, content in ai_results['tests'].items():
                test_file = tests_dir / f"{test_type}.py"
                test_file.write_text(content, encoding='utf-8')
        
        # ä¿å­˜ä»£ç æ–‡ä»¶
        if 'code' in ai_results:
            code_dir = req_dir / 'code'
            code_dir.mkdir(exist_ok=True)
            for code_type, content in ai_results['code'].items():
                code_file = code_dir / f"{code_type}.py"
                code_file.write_text(content, encoding='utf-8')
        
        # ä¿å­˜å®¡æŸ¥æŠ¥å‘Š
        if 'review' in ai_results:
            review_file = req_dir / 'code_review.md'
            review_file.write_text(ai_results['review'], encoding='utf-8')
```

### 4. æ›´æ–°Makefile

åœ¨ç°æœ‰Makefileä¸­æ·»åŠ AIå¢å¼ºé€‰é¡¹ï¼š

```makefile
# AIå¢å¼ºçš„éœ€æ±‚æµæ°´çº¿
req-ai-pipeline:
	@echo "ğŸ¤– è¿è¡ŒAIå¢å¼ºçš„éœ€æ±‚æµæ°´çº¿..."
	python scripts/req_to_test_pipeline.py --input $(REQ) --ai-enabled --ai-tasks generate_tests,implement_code,review_code

req-ai-pipeline-dry:
	@echo "ğŸ¤– é¢„è§ˆAIå¢å¼ºçš„éœ€æ±‚æµæ°´çº¿..."
	python scripts/req_to_test_pipeline.py --input $(REQ) --ai-enabled --dry-run

req-ai-tests:
	@echo "ğŸ¤– AIç”Ÿæˆæµ‹è¯•ä»£ç ..."
	python scripts/req_to_test_pipeline.py --input $(REQ) --ai-enabled --ai-tasks generate_tests

req-ai-code:
	@echo "ğŸ¤– AIå®ç°åŠŸèƒ½ä»£ç ..."
	python scripts/req_to_test_pipeline.py --input $(REQ) --ai-enabled --ai-tasks implement_code

req-ai-review:
	@echo "ğŸ¤– AIä»£ç å®¡æŸ¥..."
	python scripts/req_to_test_pipeline.py --input $(REQ) --ai-enabled --ai-tasks review_code
```

## ä½¿ç”¨æ–¹æ³•

### 1. é…ç½®AIæä¾›å•†

é€‰æ‹©ä»¥ä¸‹ä»»ä¸€æ–¹å¼ï¼š

**æ–¹å¼1ï¼šä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰**
```bash
# ç›´æ¥ä½¿ç”¨ï¼Œé»˜è®¤ä¸ºæ¨¡æ‹Ÿæ¨¡å¼
make req-ai-pipeline REQ=requirements/user_avatar.md
```

**æ–¹å¼2ï¼šé…ç½®OpenAI**
```bash
# ç¼–è¾‘ai_config.json
{
  "providers": {
    "openai": {
      "api_key": "sk-your-openai-key",
      "base_url": "https://api.openai.com/v1",
      "model": "gpt-4"
    }
  },
  "default_provider": "openai"
}
```

**æ–¹å¼3ï¼šä½¿ç”¨æœ¬åœ°Ollama**
```bash
# 1. å®‰è£…Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. ä¸‹è½½ä»£ç æ¨¡å‹
ollama pull codellama:13b

# 3. å¯åŠ¨æœåŠ¡
ollama serve

# 4. é…ç½®ai_config.json
{
  "providers": {
    "ollama": {
      "base_url": "http://localhost:11434",
      "model": "codellama:13b"
    }
  },
  "default_provider": "ollama"
}
```

### 2. è¿è¡ŒAIå¢å¼ºæµæ°´çº¿

```bash
# å®Œæ•´çš„AIå¢å¼ºæµæ°´çº¿
make req-ai-pipeline REQ=requirements/idiomatic_expressions.md

# åªç”Ÿæˆæµ‹è¯•
make req-ai-tests REQ=requirements/user_avatar.md

# åªå®ç°ä»£ç 
make req-ai-code REQ=requirements/user_avatar.md

# åªè¿›è¡Œä»£ç å®¡æŸ¥
make req-ai-review REQ=requirements/user_avatar.md

# é¢„è§ˆæ¨¡å¼ï¼ˆä¸å®é™…æ‰§è¡Œï¼‰
make req-ai-pipeline-dry REQ=requirements/user_avatar.md
```

### 3. æŸ¥çœ‹AIç”Ÿæˆçš„ç»“æœ

```bash
# AIç”Ÿæˆçš„æ–‡ä»¶ä¼šä¿å­˜åœ¨
ai_generated/
â”œâ”€â”€ user_avatar/
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ unit_test.py
â”‚   â”‚   â”œâ”€â”€ integration_test.py
â”‚   â”‚   â””â”€â”€ e2e_test.py
â”‚   â”œâ”€â”€ code/
â”‚   â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   â”œâ”€â”€ views.py
â”‚   â”‚   â””â”€â”€ components.py
â”‚   â””â”€â”€ code_review.md
```

## ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | ä¼ ç»Ÿæµæ°´çº¿ | AIå¢å¼ºæµæ°´çº¿ |
|------|------------|-------------|
| æµ‹è¯•ç”Ÿæˆ | åŸºç¡€æ¨¡æ¿ | æ™ºèƒ½ç”Ÿæˆï¼Œè¦†ç›–å…·ä½“ä¸šåŠ¡é€»è¾‘ |
| ä»£ç å®ç° | ç©ºæ¡†æ¶ | å®Œæ•´åŠŸèƒ½å®ç° |
| ä»£ç è´¨é‡ | éœ€è¦æ‰‹åŠ¨ç¼–å†™ | AIå®¡æŸ¥å’Œä¼˜åŒ–å»ºè®® |
| å¼€å‘æ•ˆç‡ | ä¸­ç­‰ | æ˜¾è‘—æå‡ |
| å­¦ä¹ æˆæœ¬ | ä½ | ä¸­ç­‰ |
| æˆæœ¬ | å…è´¹ | éœ€è¦APIè´¹ç”¨ï¼ˆæˆ–æœ¬åœ°éƒ¨ç½²ï¼‰ |

## æ€»ç»“

é€šè¿‡è¿™ä¸ªAIé›†æˆæ–¹æ¡ˆï¼Œä½ å¯ä»¥ï¼š

1. **æ— ç¼é›†æˆ**ï¼šåœ¨ç°æœ‰æµæ°´çº¿åŸºç¡€ä¸Šæ·»åŠ AIåŠŸèƒ½
2. **çµæ´»é…ç½®**ï¼šæ”¯æŒå¤šç§AIæä¾›å•†ï¼ˆOpenAIã€Claudeã€Ollamaã€æ¨¡æ‹Ÿæ¨¡å¼ï¼‰
3. **æ¸è¿›å¼é‡‡ç”¨**ï¼šå¯ä»¥é€‰æ‹©æ€§å¯ç”¨AIåŠŸèƒ½
4. **æˆæœ¬å¯æ§**ï¼šæä¾›å…è´¹çš„æ¨¡æ‹Ÿæ¨¡å¼å’Œæœ¬åœ°éƒ¨ç½²é€‰é¡¹
5. **è´¨é‡ä¿è¯**ï¼šAIç”Ÿæˆçš„ä»£ç ä¼šç»è¿‡å®¡æŸ¥å’Œä¼˜åŒ–

è¿™æ ·ä½ å°±å¯ä»¥åœ¨ä¸æä¾›APIå¯†é’¥çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡æ¨¡æ‹Ÿæ¨¡å¼ä½“éªŒå®Œæ•´çš„AIå¢å¼ºå¼€å‘æµç¨‹ï¼Œæˆ–è€…é…ç½®è‡ªå·±çš„AIæœåŠ¡æ¥è·å¾—çœŸå®çš„AIè¾…åŠ©å¼€å‘ä½“éªŒã€‚