#!/usr/bin/env python3
"""
ç®€å•çš„HTTP APIæµ‹è¯•è„šæœ¬
"""

import requests
import json
import time

def test_backend_server():
    """æµ‹è¯•åç«¯æœåŠ¡å™¨"""
    try:
        response = requests.get('http://localhost:8000/api/v1/english/news/', timeout=5)
        if response.status_code == 200:
            print("âœ… åç«¯æœåŠ¡å™¨è¿è¡Œæ­£å¸¸")
            return True
        else:
            print(f"âŒ åç«¯æœåŠ¡å™¨å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ åç«¯æœåŠ¡å™¨è¿æ¥å¤±è´¥: {e}")
        return False

def test_news_crawling():
    """æµ‹è¯•æ–°é—»çˆ¬å–API"""
    try:
        test_data = {
            "sources": ["uk.BBC", "us.TechCrunch"],
            "max_articles": 2,
            "timeout": 60
        }
        
        print("ğŸ”„ å¼€å§‹æµ‹è¯•æ–°é—»çˆ¬å–API...")
        print(f"   æµ‹è¯•æ•°æ®: {test_data}")
        
        response = requests.post(
            'http://localhost:8000/api/v1/english/news/crawl/',
            json=test_data,
            timeout=120
        )
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… æ–°é—»çˆ¬å–APIæˆåŠŸ!")
            print(f"   å“åº”æ•°æ®: {json.dumps(result, indent=2, ensure_ascii=False)}")
            return True
        else:
            print(f"âŒ æ–°é—»çˆ¬å–APIå¤±è´¥: {response.status_code}")
            print(f"   é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ æ–°é—»çˆ¬å–APIè¯·æ±‚å¤±è´¥: {e}")
        return False

def test_news_list():
    """æµ‹è¯•æ–°é—»åˆ—è¡¨API"""
    try:
        response = requests.get('http://localhost:8000/api/v1/english/news/', timeout=10)
        if response.status_code == 200:
            data = response.json()
            news_count = len(data.get('results', []))
            print(f"âœ… è·å–æ–°é—»åˆ—è¡¨æˆåŠŸï¼Œå…± {news_count} æ¡æ–°é—»")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
            news_with_images = 0
            for news in data.get('results', []):
                if news.get('image_url'):
                    news_with_images += 1
            
            print(f"   å…¶ä¸­ {news_with_images} æ¡æ–°é—»åŒ…å«å›¾ç‰‡")
            return True
        else:
            print(f"âŒ è·å–æ–°é—»åˆ—è¡¨å¤±è´¥: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ è·å–æ–°é—»åˆ—è¡¨è¯·æ±‚å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 60)
    print("æ–°é—»çˆ¬å–åŠŸèƒ½APIæµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # æµ‹è¯•æœåŠ¡å™¨çŠ¶æ€
    print("1. æµ‹è¯•åç«¯æœåŠ¡å™¨çŠ¶æ€")
    print("-" * 30)
    backend_ok = test_backend_server()
    print()
    
    if not backend_ok:
        print("âŒ åç«¯æœåŠ¡å™¨æœªè¿è¡Œï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
        return
    
    # æµ‹è¯•æ–°é—»çˆ¬å–
    print("2. æµ‹è¯•æ–°é—»çˆ¬å–API")
    print("-" * 30)
    crawling_ok = test_news_crawling()
    print()
    
    # æµ‹è¯•æ–°é—»åˆ—è¡¨
    print("3. æµ‹è¯•æ–°é—»åˆ—è¡¨API")
    print("-" * 30)
    list_ok = test_news_list()
    print()
    
    # æµ‹è¯•ç»“æœæ€»ç»“
    print("4. æµ‹è¯•ç»“æœæ€»ç»“")
    print("-" * 30)
    if backend_ok and crawling_ok and list_ok:
        print("ğŸ‰ æ‰€æœ‰APIæµ‹è¯•é€šè¿‡ï¼æ–°é—»çˆ¬å–åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
    else:
        print("âš ï¸  éƒ¨åˆ†APIæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç›¸å…³åŠŸèƒ½")
    
    print("=" * 60)

if __name__ == "__main__":
    main()
