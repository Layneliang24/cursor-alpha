"""
æµ‹è¯•è´¨é‡ç›‘æ§å™¨

ç›‘æ§å’Œåˆ†ææµ‹è¯•è´¨é‡æŒ‡æ ‡ï¼š
1. æµ‹è¯•è¦†ç›–ç‡ç›‘æ§
2. æµ‹è¯•æ‰§è¡Œæ—¶é—´åˆ†æ
3. æµ‹è¯•ç¨³å®šæ€§åˆ†æ
4. æµ‹è¯•è´¨é‡è¯„åˆ†
5. è´¨é‡è¶‹åŠ¿æŠ¥å‘Š
"""

import os
import json
import time
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
import subprocess
import xml.etree.ElementTree as ET


@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡æ•°æ®ç»“æ„"""
    timestamp: datetime
    total_tests: int
    passed_tests: int
    failed_tests: int
    skipped_tests: int
    pass_rate: float
    execution_time: float
    coverage_percentage: float
    avg_test_time: float
    flaky_tests: int
    new_tests: int
    removed_tests: int
    quality_score: float


@dataclass
class TestStability:
    """æµ‹è¯•ç¨³å®šæ€§æ•°æ®"""
    test_name: str
    success_rate: float
    avg_duration: float
    failure_count: int
    last_failure: Optional[datetime]
    is_flaky: bool


class TestQualityMonitor:
    """æµ‹è¯•è´¨é‡ç›‘æ§å™¨"""
    
    def __init__(self, db_path: str = "tests/reports/quality.db"):
        self.db_path = Path(db_path)
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS quality_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    total_tests INTEGER NOT NULL,
                    passed_tests INTEGER NOT NULL,
                    failed_tests INTEGER NOT NULL,
                    skipped_tests INTEGER NOT NULL,
                    pass_rate REAL NOT NULL,
                    execution_time REAL NOT NULL,
                    coverage_percentage REAL,
                    avg_test_time REAL NOT NULL,
                    flaky_tests INTEGER DEFAULT 0,
                    new_tests INTEGER DEFAULT 0,
                    removed_tests INTEGER DEFAULT 0,
                    quality_score REAL NOT NULL
                )
            """)
            
            conn.execute("""
                CREATE TABLE IF NOT EXISTS test_stability (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    test_name TEXT NOT NULL,
                    timestamp TEXT NOT NULL,
                    duration REAL NOT NULL,
                    status TEXT NOT NULL,
                    error_message TEXT
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_timestamp ON quality_metrics(timestamp)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_test_name ON test_stability(test_name)
            """)
    
    def record_test_run(self, junit_xml_path: str, coverage_data: Optional[Dict] = None) -> QualityMetrics:
        """è®°å½•æµ‹è¯•è¿è¡Œç»“æœ"""
        # è§£ææµ‹è¯•ç»“æœ
        metrics = self._parse_test_results(junit_xml_path, coverage_data)
        
        # åˆ†ææµ‹è¯•ç¨³å®šæ€§
        self._analyze_test_stability(junit_xml_path)
        
        # è®¡ç®—è´¨é‡è¯„åˆ†
        metrics.quality_score = self._calculate_quality_score(metrics)
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        self._save_metrics(metrics)
        
        return metrics
    
    def _parse_test_results(self, junit_xml_path: str, coverage_data: Optional[Dict]) -> QualityMetrics:
        """è§£ææµ‹è¯•ç»“æœ"""
        tree = ET.parse(junit_xml_path)
        root = tree.getroot()
        
        total_tests = 0
        passed_tests = 0
        failed_tests = 0
        skipped_tests = 0
        total_time = 0.0
        
        # è§£ææµ‹è¯•å¥—ä»¶
        for testsuite in root.findall('.//testsuite'):
            suite_tests = int(testsuite.get('tests', 0))
            suite_failures = int(testsuite.get('failures', 0))
            suite_errors = int(testsuite.get('errors', 0))
            suite_skipped = int(testsuite.get('skipped', 0))
            suite_time = float(testsuite.get('time', 0))
            
            total_tests += suite_tests
            failed_tests += suite_failures + suite_errors
            skipped_tests += suite_skipped
            total_time += suite_time
        
        passed_tests = total_tests - failed_tests - skipped_tests
        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
        avg_test_time = (total_time / total_tests) if total_tests > 0 else 0
        
        # è·å–è¦†ç›–ç‡
        coverage_percentage = 0.0
        if coverage_data:
            coverage_percentage = coverage_data.get('totals', {}).get('percent_covered', 0.0)
        
        return QualityMetrics(
            timestamp=datetime.now(),
            total_tests=total_tests,
            passed_tests=passed_tests,
            failed_tests=failed_tests,
            skipped_tests=skipped_tests,
            pass_rate=pass_rate,
            execution_time=total_time,
            coverage_percentage=coverage_percentage,
            avg_test_time=avg_test_time,
            flaky_tests=0,  # ç¨åè®¡ç®—
            new_tests=0,    # ç¨åè®¡ç®—
            removed_tests=0, # ç¨åè®¡ç®—
            quality_score=0.0  # ç¨åè®¡ç®—
        )
    
    def _analyze_test_stability(self, junit_xml_path: str):
        """åˆ†ææµ‹è¯•ç¨³å®šæ€§"""
        tree = ET.parse(junit_xml_path)
        root = tree.getroot()
        
        with sqlite3.connect(self.db_path) as conn:
            for testsuite in root.findall('.//testsuite'):
                for testcase in testsuite.findall('.//testcase'):
                    test_name = f"{testsuite.get('name', '')}.{testcase.get('name', '')}"
                    duration = float(testcase.get('time', 0))
                    
                    # ç¡®å®šæµ‹è¯•çŠ¶æ€
                    if testcase.find('failure') is not None:
                        status = 'failed'
                        error_msg = testcase.find('failure').get('message', '')
                    elif testcase.find('error') is not None:
                        status = 'error'
                        error_msg = testcase.find('error').get('message', '')
                    elif testcase.find('skipped') is not None:
                        status = 'skipped'
                        error_msg = ''
                    else:
                        status = 'passed'
                        error_msg = ''
                    
                    # è®°å½•æµ‹è¯•æ‰§è¡Œ
                    conn.execute("""
                        INSERT INTO test_stability 
                        (test_name, timestamp, duration, status, error_message)
                        VALUES (?, ?, ?, ?, ?)
                    """, (test_name, datetime.now().isoformat(), duration, status, error_msg))
    
    def _calculate_quality_score(self, metrics: QualityMetrics) -> float:
        """è®¡ç®—è´¨é‡è¯„åˆ† (0-100)"""
        # æƒé‡é…ç½®
        weights = {
            'pass_rate': 0.4,      # é€šè¿‡ç‡æƒé‡40%
            'coverage': 0.3,       # è¦†ç›–ç‡æƒé‡30%
            'stability': 0.2,      # ç¨³å®šæ€§æƒé‡20%
            'performance': 0.1     # æ€§èƒ½æƒé‡10%
        }
        
        # é€šè¿‡ç‡è¯„åˆ†
        pass_rate_score = metrics.pass_rate
        
        # è¦†ç›–ç‡è¯„åˆ†
        coverage_score = min(metrics.coverage_percentage, 100)
        
        # ç¨³å®šæ€§è¯„åˆ† (åŸºäºflakyæµ‹è¯•æ•°é‡)
        stability_score = max(0, 100 - (metrics.flaky_tests * 10))
        
        # æ€§èƒ½è¯„åˆ† (åŸºäºå¹³å‡æµ‹è¯•æ—¶é—´)
        # å‡è®¾ç†æƒ³çš„æµ‹è¯•æ—¶é—´æ˜¯0.1ç§’ï¼Œè¶…è¿‡1ç§’å¼€å§‹æ‰£åˆ†
        if metrics.avg_test_time <= 0.1:
            performance_score = 100
        elif metrics.avg_test_time <= 1.0:
            performance_score = 100 - (metrics.avg_test_time - 0.1) * 50
        else:
            performance_score = max(0, 50 - (metrics.avg_test_time - 1.0) * 10)
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        quality_score = (
            pass_rate_score * weights['pass_rate'] +
            coverage_score * weights['coverage'] +
            stability_score * weights['stability'] +
            performance_score * weights['performance']
        )
        
        return round(quality_score, 2)
    
    def _save_metrics(self, metrics: QualityMetrics):
        """ä¿å­˜æŒ‡æ ‡åˆ°æ•°æ®åº“"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                INSERT INTO quality_metrics 
                (timestamp, total_tests, passed_tests, failed_tests, skipped_tests,
                 pass_rate, execution_time, coverage_percentage, avg_test_time,
                 flaky_tests, new_tests, removed_tests, quality_score)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                metrics.timestamp.isoformat(),
                metrics.total_tests,
                metrics.passed_tests,
                metrics.failed_tests,
                metrics.skipped_tests,
                metrics.pass_rate,
                metrics.execution_time,
                metrics.coverage_percentage,
                metrics.avg_test_time,
                metrics.flaky_tests,
                metrics.new_tests,
                metrics.removed_tests,
                metrics.quality_score
            ))
    
    def get_flaky_tests(self, days: int = 7, min_runs: int = 5) -> List[TestStability]:
        """è·å–ä¸ç¨³å®šçš„æµ‹è¯•"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT test_name,
                       COUNT(*) as total_runs,
                       SUM(CASE WHEN status = 'passed' THEN 1 ELSE 0 END) as passed_runs,
                       AVG(duration) as avg_duration,
                       SUM(CASE WHEN status != 'passed' THEN 1 ELSE 0 END) as failure_count,
                       MAX(CASE WHEN status != 'passed' THEN timestamp ELSE NULL END) as last_failure
                FROM test_stability
                WHERE timestamp > datetime('now', '-{} days')
                GROUP BY test_name
                HAVING total_runs >= ?
            """.format(days), (min_runs,))
            
            flaky_tests = []
            for row in cursor:
                test_name, total_runs, passed_runs, avg_duration, failure_count, last_failure = row
                success_rate = (passed_runs / total_runs * 100) if total_runs > 0 else 0
                
                # è®¤ä¸ºæˆåŠŸç‡ä½äº90%çš„æµ‹è¯•ä¸ºä¸ç¨³å®š
                is_flaky = success_rate < 90.0
                
                if is_flaky:
                    flaky_tests.append(TestStability(
                        test_name=test_name,
                        success_rate=success_rate,
                        avg_duration=avg_duration,
                        failure_count=failure_count,
                        last_failure=datetime.fromisoformat(last_failure) if last_failure else None,
                        is_flaky=is_flaky
                    ))
            
            return sorted(flaky_tests, key=lambda x: x.success_rate)
    
    def get_quality_trend(self, days: int = 30) -> List[QualityMetrics]:
        """è·å–è´¨é‡è¶‹åŠ¿"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.execute("""
                SELECT * FROM quality_metrics
                WHERE timestamp > datetime('now', '-{} days')
                ORDER BY timestamp DESC
            """.format(days))
            
            trends = []
            for row in cursor:
                _, timestamp, total_tests, passed_tests, failed_tests, skipped_tests, \
                pass_rate, execution_time, coverage_percentage, avg_test_time, \
                flaky_tests, new_tests, removed_tests, quality_score = row
                
                trends.append(QualityMetrics(
                    timestamp=datetime.fromisoformat(timestamp),
                    total_tests=total_tests,
                    passed_tests=passed_tests,
                    failed_tests=failed_tests,
                    skipped_tests=skipped_tests,
                    pass_rate=pass_rate,
                    execution_time=execution_time,
                    coverage_percentage=coverage_percentage,
                    avg_test_time=avg_test_time,
                    flaky_tests=flaky_tests,
                    new_tests=new_tests,
                    removed_tests=removed_tests,
                    quality_score=quality_score
                ))
            
            return trends
    
    def generate_quality_report(self, output_path: str = "tests/reports/quality_report.json"):
        """ç”Ÿæˆè´¨é‡æŠ¥å‘Š"""
        # è·å–æœ€æ–°æŒ‡æ ‡
        latest_metrics = self.get_quality_trend(days=1)
        current_metrics = latest_metrics[0] if latest_metrics else None
        
        # è·å–å†å²è¶‹åŠ¿
        trend_metrics = self.get_quality_trend(days=30)
        
        # è·å–ä¸ç¨³å®šæµ‹è¯•
        flaky_tests = self.get_flaky_tests(days=7)
        
        # è®¡ç®—è¶‹åŠ¿åˆ†æ
        trend_analysis = self._analyze_trends(trend_metrics)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'generated_at': datetime.now().isoformat(),
            'current_metrics': asdict(current_metrics) if current_metrics else None,
            'trend_analysis': trend_analysis,
            'flaky_tests': [asdict(test) for test in flaky_tests[:10]],  # å‰10ä¸ªæœ€ä¸ç¨³å®šçš„æµ‹è¯•
            'recommendations': self._generate_recommendations(current_metrics, flaky_tests)
        }
        
        # ä¿å­˜æŠ¥å‘Š
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        return report
    
    def _analyze_trends(self, metrics: List[QualityMetrics]) -> Dict[str, Any]:
        """åˆ†æè¶‹åŠ¿"""
        if len(metrics) < 2:
            return {'status': 'insufficient_data'}
        
        # è®¡ç®—å˜åŒ–è¶‹åŠ¿
        recent = metrics[0]
        older = metrics[-1]
        
        pass_rate_change = recent.pass_rate - older.pass_rate
        coverage_change = recent.coverage_percentage - older.coverage_percentage
        quality_change = recent.quality_score - older.quality_score
        
        return {
            'period_days': (recent.timestamp - older.timestamp).days,
            'pass_rate_change': round(pass_rate_change, 2),
            'coverage_change': round(coverage_change, 2),
            'quality_change': round(quality_change, 2),
            'trend_direction': 'improving' if quality_change > 0 else 'declining' if quality_change < 0 else 'stable'
        }
    
    def _generate_recommendations(self, current_metrics: Optional[QualityMetrics], 
                                flaky_tests: List[TestStability]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        recommendations = []
        
        if not current_metrics:
            return ['éœ€è¦æ›´å¤šæµ‹è¯•æ•°æ®æ¥ç”Ÿæˆå»ºè®®']
        
        # é€šè¿‡ç‡å»ºè®®
        if current_metrics.pass_rate < 95:
            recommendations.append(f"é€šè¿‡ç‡ä¸º{current_metrics.pass_rate:.1f}%ï¼Œå»ºè®®ä¿®å¤å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹")
        
        # è¦†ç›–ç‡å»ºè®®
        if current_metrics.coverage_percentage < 80:
            recommendations.append(f"ä»£ç è¦†ç›–ç‡ä¸º{current_metrics.coverage_percentage:.1f}%ï¼Œå»ºè®®å¢åŠ æµ‹è¯•ç”¨ä¾‹")
        
        # æ€§èƒ½å»ºè®®
        if current_metrics.avg_test_time > 1.0:
            recommendations.append(f"å¹³å‡æµ‹è¯•æ—¶é—´ä¸º{current_metrics.avg_test_time:.2f}ç§’ï¼Œå»ºè®®ä¼˜åŒ–æµ‹è¯•æ€§èƒ½")
        
        # ç¨³å®šæ€§å»ºè®®
        if len(flaky_tests) > 0:
            recommendations.append(f"å‘ç°{len(flaky_tests)}ä¸ªä¸ç¨³å®šæµ‹è¯•ï¼Œå»ºè®®ä¿®å¤ä»¥æé«˜æµ‹è¯•å¯é æ€§")
        
        # è´¨é‡è¯„åˆ†å»ºè®®
        if current_metrics.quality_score < 80:
            recommendations.append("æ•´ä½“è´¨é‡è¯„åˆ†åä½ï¼Œå»ºè®®é‡ç‚¹å…³æ³¨é€šè¿‡ç‡å’Œè¦†ç›–ç‡")
        
        return recommendations
    
    def check_quality_gates(self, metrics: QualityMetrics) -> Tuple[bool, List[str]]:
        """æ£€æŸ¥è´¨é‡é—¨ç¦"""
        failures = []
        
        # è´¨é‡é—¨ç¦è§„åˆ™
        gates = {
            'min_pass_rate': 90.0,
            'min_coverage': 70.0,
            'max_avg_test_time': 2.0,
            'max_flaky_tests': 5,
            'min_quality_score': 75.0
        }
        
        if metrics.pass_rate < gates['min_pass_rate']:
            failures.append(f"é€šè¿‡ç‡{metrics.pass_rate:.1f}%ä½äºè¦æ±‚çš„{gates['min_pass_rate']}%")
        
        if metrics.coverage_percentage < gates['min_coverage']:
            failures.append(f"è¦†ç›–ç‡{metrics.coverage_percentage:.1f}%ä½äºè¦æ±‚çš„{gates['min_coverage']}%")
        
        if metrics.avg_test_time > gates['max_avg_test_time']:
            failures.append(f"å¹³å‡æµ‹è¯•æ—¶é—´{metrics.avg_test_time:.2f}ç§’è¶…è¿‡é™åˆ¶çš„{gates['max_avg_test_time']}ç§’")
        
        if metrics.flaky_tests > gates['max_flaky_tests']:
            failures.append(f"ä¸ç¨³å®šæµ‹è¯•æ•°é‡{metrics.flaky_tests}è¶…è¿‡é™åˆ¶çš„{gates['max_flaky_tests']}ä¸ª")
        
        if metrics.quality_score < gates['min_quality_score']:
            failures.append(f"è´¨é‡è¯„åˆ†{metrics.quality_score:.1f}ä½äºè¦æ±‚çš„{gates['min_quality_score']}")
        
        return len(failures) == 0, failures


# å‘½ä»¤è¡Œå·¥å…·
def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æµ‹è¯•è´¨é‡ç›‘æ§å™¨")
    parser.add_argument('--junit-xml', required=True, help='JUnit XMLæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--coverage-json', help='è¦†ç›–ç‡JSONæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--output', default='tests/reports/quality_report.json', help='è¾“å‡ºæŠ¥å‘Šè·¯å¾„')
    parser.add_argument('--check-gates', action='store_true', help='æ£€æŸ¥è´¨é‡é—¨ç¦')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç›‘æ§å™¨
    monitor = TestQualityMonitor()
    
    # è¯»å–è¦†ç›–ç‡æ•°æ®
    coverage_data = None
    if args.coverage_json and os.path.exists(args.coverage_json):
        with open(args.coverage_json, 'r') as f:
            coverage_data = json.load(f)
    
    # è®°å½•æµ‹è¯•è¿è¡Œ
    metrics = monitor.record_test_run(args.junit_xml, coverage_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = monitor.generate_quality_report(args.output)
    
    # æ£€æŸ¥è´¨é‡é—¨ç¦
    if args.check_gates:
        passed, failures = monitor.check_quality_gates(metrics)
        
        print(f"è´¨é‡é—¨ç¦æ£€æŸ¥: {'âœ… é€šè¿‡' if passed else 'âŒ å¤±è´¥'}")
        if failures:
            print("å¤±è´¥åŸå› :")
            for failure in failures:
                print(f"  - {failure}")
        
        return 0 if passed else 1
    
    print(f"âœ… è´¨é‡æŠ¥å‘Šå·²ç”Ÿæˆ: {args.output}")
    print(f"ğŸ“Š è´¨é‡è¯„åˆ†: {metrics.quality_score:.1f}/100")
    return 0


if __name__ == '__main__':
    exit(main())


print("âœ… æµ‹è¯•è´¨é‡ç›‘æ§å™¨åˆ›å»ºå®Œæˆ")