"""
ä¼˜åŒ–çš„æµ‹è¯•è¿è¡Œå™¨

æä¾›å¤šç§æµ‹è¯•è¿è¡Œæ¨¡å¼ï¼š
1. å¿«é€Ÿæµ‹è¯• - åªè¿è¡Œæ ¸å¿ƒåŠŸèƒ½æµ‹è¯•
2. å®Œæ•´æµ‹è¯• - è¿è¡Œæ‰€æœ‰æµ‹è¯•
3. å¹¶è¡Œæµ‹è¯• - ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿæµ‹è¯•
4. è¦†ç›–ç‡æµ‹è¯• - ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
5. æ€§èƒ½æµ‹è¯• - ä¸“é—¨çš„æ€§èƒ½å›å½’æµ‹è¯•
"""

import os
import sys
import time
import subprocess
from pathlib import Path
from typing import Dict, List, Optional
import argparse
from dataclasses import dataclass
from enum import Enum


class TestLevel(Enum):
    """æµ‹è¯•çº§åˆ«"""
    SMOKE = "smoke"      # å†’çƒŸæµ‹è¯• - æœ€åŸºæœ¬çš„åŠŸèƒ½
    FAST = "fast"        # å¿«é€Ÿæµ‹è¯• - æ ¸å¿ƒåŠŸèƒ½
    FULL = "full"        # å®Œæ•´æµ‹è¯• - æ‰€æœ‰æµ‹è¯•
    FRONTEND = "frontend"  # å‰ç«¯æµ‹è¯•
    REGRESSION = "regression"  # å›å½’æµ‹è¯•
    PERFORMANCE = "performance"  # æ€§èƒ½æµ‹è¯•


@dataclass
class TestSuite:
    """æµ‹è¯•å¥—ä»¶å®šä¹‰"""
    name: str
    description: str
    test_paths: List[str]
    expected_time: int  # é¢„æœŸæ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
    parallel_safe: bool = True  # æ˜¯å¦æ”¯æŒå¹¶è¡Œæ‰§è¡Œ


class TestConfiguration:
    """æµ‹è¯•é…ç½®ç®¡ç†"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.test_root = Path(__file__).parent
        
        # å®šä¹‰æµ‹è¯•å¥—ä»¶
        self.test_suites = {
            TestLevel.SMOKE: TestSuite(
                name="å†’çƒŸæµ‹è¯•",
                description="æœ€åŸºæœ¬çš„åŠŸèƒ½éªŒè¯ï¼Œç¡®ä¿ç³»ç»Ÿå¯ä»¥å¯åŠ¨",
                test_paths=[
                    "tests/unit/test_basic.py",
                    "tests/unit/test_mysql_connection.py",
                    "tests/unit/test_simple.py"
                ],
                expected_time=10,
                parallel_safe=True
            ),
            
            TestLevel.FAST: TestSuite(
                name="å¿«é€Ÿæµ‹è¯•",
                description="æ ¸å¿ƒåŠŸèƒ½æµ‹è¯•ï¼Œé€‚åˆå¼€å‘è¿‡ç¨‹ä¸­é¢‘ç¹è¿è¡Œ",
                test_paths=[
                    "tests/unit/test_basic.py",
                    "tests/unit/test_models.py", 
                    "tests/unit/test_mysql_connection.py",
                    "tests/unit/test_simple.py",
                    "tests/unit/test_data_analysis.py",
                    "tests/unit/test_links_module.py",
                    "tests/unit/test_common_module.py",
                    "tests/unit/test_user_auth.py",
                    "tests/regression/auth/test_permissions.py",
                    "tests/regression/auth/test_user_authentication.py"
                ],
                expected_time=45,
                parallel_safe=True
            ),
            
            TestLevel.FRONTEND: TestSuite(
                name="å‰ç«¯æµ‹è¯•",
                description="å‰ç«¯ç»„ä»¶å’ŒåŠŸèƒ½æµ‹è¯•",
                test_paths=[
                    "frontend/src/components/__tests__/",
                    "frontend/src/utils/__tests__/"
                ],
                expected_time=30,
                parallel_safe=True
            ),
            
            TestLevel.REGRESSION: TestSuite(
                name="å›å½’æµ‹è¯•",
                description="ç¡®ä¿æ–°å˜æ›´ä¸ä¼šç ´åç°æœ‰åŠŸèƒ½",
                test_paths=[
                    "tests/regression/",
                    "tests/unit/test_data_analysis.py",
                    "tests/unit/test_user_auth.py",
                    "tests/integration/test_api.py"
                ],
                expected_time=60,
                parallel_safe=True
            ),
            
            TestLevel.PERFORMANCE: TestSuite(
                name="æ€§èƒ½æµ‹è¯•",
                description="æ€§èƒ½å›å½’æµ‹è¯•å’ŒåŸºå‡†æµ‹è¯•",
                test_paths=[
                    "tests/performance/",
                    "tests/data_management/test_data_factory.py::TestDataFactoryIntegrationTest::test_bulk_data_performance"
                ],
                expected_time=30,
                parallel_safe=False
            ),
            
            TestLevel.FULL: TestSuite(
                name="å®Œæ•´æµ‹è¯•",
                description="è¿è¡Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹",
                test_paths=["tests/"],
                expected_time=180,
                parallel_safe=False
            )
        }
    
    def get_stable_tests(self) -> List[str]:
        """è·å–ç¨³å®šæµ‹è¯•åˆ—è¡¨"""
        return [
            "tests/unit/test_basic.py",
            "tests/unit/test_models.py",
            "tests/unit/test_mysql_connection.py", 
            "tests/unit/test_simple.py",
            "tests/unit/test_data_analysis.py",
            "tests/unit/test_cnn_crawler.py",
            "tests/unit/test_news_visibility_removal.py",
            "tests/unit/test_fundus_crawler.py",
            "tests/unit/test_links_module.py",
            "tests/unit/test_common_module.py",
            "tests/integration/test_news_api.py",
            "tests/integration/test_fixes_verification.py",
            "tests/regression/english/test_pronunciation.py",
            "tests/regression/english/test_data_analysis_regression.py",
            "tests/regression/auth/test_permissions.py",
            "tests/regression/auth/test_user_authentication.py",
            "tests/unit/test_jobs.py",
            "tests/unit/test_todos.py",
            "tests/unit/test_typing_practice_submit.py"
        ]


class TestRunner:
    """ä¼˜åŒ–çš„æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.config = TestConfiguration()
        self.start_time = None
        self.results = {}
    
    def run_tests(self, 
                  level: TestLevel = TestLevel.FAST,
                  parallel: bool = False,
                  coverage: bool = False,
                  verbose: bool = True,
                  fail_fast: bool = False,
                  custom_paths: Optional[List[str]] = None) -> Dict:
        """
        è¿è¡Œæµ‹è¯•
        
        Args:
            level: æµ‹è¯•çº§åˆ«
            parallel: æ˜¯å¦å¹¶è¡Œæ‰§è¡Œ
            coverage: æ˜¯å¦ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
            verbose: æ˜¯å¦è¯¦ç»†è¾“å‡º
            fail_fast: æ˜¯å¦é‡åˆ°å¤±è´¥ç«‹å³åœæ­¢
            custom_paths: è‡ªå®šä¹‰æµ‹è¯•è·¯å¾„
            
        Returns:
            æµ‹è¯•ç»“æœå­—å…¸
        """
        self.start_time = time.time()
        
        # è·å–æµ‹è¯•å¥—ä»¶
        if custom_paths:
            suite = TestSuite(
                name="è‡ªå®šä¹‰æµ‹è¯•",
                description="ç”¨æˆ·æŒ‡å®šçš„æµ‹è¯•è·¯å¾„",
                test_paths=custom_paths,
                expected_time=60,
                parallel_safe=True
            )
        else:
            suite = self.config.test_suites[level]
            
        # ç‰¹æ®Šå¤„ç†å‰ç«¯æµ‹è¯•
        if level == TestLevel.FRONTEND:
            return self._run_frontend_tests(suite, parallel, coverage, verbose, fail_fast)
        
        print(f"ğŸš€ å¼€å§‹æ‰§è¡Œ {suite.name}")
        print(f"ğŸ“ æè¿°: {suite.description}")
        print(f"â±ï¸  é¢„æœŸæ—¶é—´: {suite.expected_time}ç§’")
        print(f"ğŸ“ æµ‹è¯•è·¯å¾„: {len(suite.test_paths)}ä¸ª")
        
        if parallel and suite.parallel_safe:
            print("âš¡ å¹¶è¡Œæ¨¡å¼: å¯ç”¨")
        
        # æ„å»ºpytestå‘½ä»¤
        cmd = self._build_pytest_command(
            suite, parallel, coverage, verbose, fail_fast
        )
        
        # æ‰§è¡Œæµ‹è¯•
        result = self._execute_tests(cmd)
        
        # å¤„ç†ç»“æœ
        execution_time = time.time() - self.start_time
        self.results = {
            'suite_name': suite.name,
            'execution_time': execution_time,
            'expected_time': suite.expected_time,
            'success': result['returncode'] == 0,
            'output': result['output'],
            'error': result['error']
        }
        
        # è¾“å‡ºç»“æœ
        self._print_results()
        
        # å¦‚æœå¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        if not self.results['success'] and verbose:
            print("\n" + "="*60)
            print("ğŸ” é”™è¯¯è¯¦æƒ…:")
            print("="*60)
            if self.results['error']:
                print("STDERR:")
                print(self.results['error'])
            if self.results['output']:
                print("STDOUT:")
                print(self.results['output'])
        
        return self.results
    
    def _run_frontend_tests(self, suite: TestSuite, parallel: bool, 
                           coverage: bool, verbose: bool, fail_fast: bool) -> Dict:
        """è¿è¡Œå‰ç«¯æµ‹è¯•"""
        print(f"ğŸŒ å¼€å§‹æ‰§è¡Œå‰ç«¯æµ‹è¯•...")
        
        try:
            # è°ƒç”¨å‰ç«¯æµ‹è¯•è¿è¡Œå™¨
            frontend_runner_path = self.config.project_root / "tests" / "frontend_test_runner.py"
            
            if not frontend_runner_path.exists():
                return {
                    'suite_name': suite.name,
                    'execution_time': 0,
                    'expected_time': suite.expected_time,
                    'success': False,
                    'output': '',
                    'error': 'å‰ç«¯æµ‹è¯•è¿è¡Œå™¨ä¸å­˜åœ¨'
                }
            
            # æ„å»ºå‰ç«¯æµ‹è¯•å‘½ä»¤
            cmd = ['python', str(frontend_runner_path)]
            
            if coverage:
                cmd.append('--coverage')
            else:
                cmd.append('--no-coverage')
                
            if verbose:
                cmd.append('--verbose')
                
            # æ‰§è¡Œå‰ç«¯æµ‹è¯•
            result = subprocess.run(
                cmd,
                cwd=self.config.project_root,
                capture_output=True,
                text=True,
                timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
            )
            
            execution_time = time.time() - self.start_time
            
            return {
                'suite_name': suite.name,
                'execution_time': execution_time,
                'expected_time': suite.expected_time,
                'success': result.returncode == 0,
                'output': result.stdout,
                'error': result.stderr
            }
            
        except Exception as e:
            execution_time = time.time() - self.start_time
            return {
                'suite_name': suite.name,
                'execution_time': execution_time,
                'expected_time': suite.expected_time,
                'success': False,
                'output': '',
                'error': f'å‰ç«¯æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}'
            }
    
    def _build_pytest_command(self, suite: TestSuite, parallel: bool, 
                            coverage: bool, verbose: bool, fail_fast: bool) -> List[str]:
        """æ„å»ºpytestå‘½ä»¤"""
        cmd = ['python', '-m', 'pytest']
        
        # æ·»åŠ æµ‹è¯•è·¯å¾„
        cmd.extend(suite.test_paths)
        
        # å¹¶è¡Œæ‰§è¡Œ
        if parallel and suite.parallel_safe:
            try:
                import pytest_xdist
                cmd.extend(['-n', 'auto'])  # è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°
            except ImportError:
                print("âš ï¸  è­¦å‘Š: pytest-xdistæœªå®‰è£…ï¼Œè·³è¿‡å¹¶è¡Œæ‰§è¡Œ")
        
        # è¦†ç›–ç‡æŠ¥å‘Š
        if coverage:
            cmd.extend([
                '--cov=backend',
                '--cov-report=html:tests/coverage_html',
                '--cov-report=term-missing',
                '--cov-fail-under=80'
            ])
        
        # è¯¦ç»†è¾“å‡º
        if verbose:
            cmd.append('-v')
        else:
            cmd.append('-q')
        
        # å¿«é€Ÿå¤±è´¥
        if fail_fast:
            cmd.append('-x')
        
        # å…¶ä»–æœ‰ç”¨çš„é€‰é¡¹
        cmd.extend([
            '--tb=short',  # ç®€çŸ­çš„é”™è¯¯è¿½è¸ª
            '--disable-warnings',  # ç¦ç”¨è­¦å‘Š
            '--cache-clear',  # æ¸…é™¤ç¼“å­˜
        ])
        
        return cmd
    
    def _execute_tests(self, cmd: List[str]) -> Dict:
        """æ‰§è¡Œæµ‹è¯•å‘½ä»¤"""
        try:
            result = subprocess.run(
                cmd,
                cwd=self.config.project_root,
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†é’Ÿè¶…æ—¶
            )
            
            return {
                'returncode': result.returncode,
                'output': result.stdout,
                'error': result.stderr
            }
            
        except subprocess.TimeoutExpired:
            return {
                'returncode': -1,
                'output': '',
                'error': 'æµ‹è¯•æ‰§è¡Œè¶…æ—¶'
            }
        except Exception as e:
            return {
                'returncode': -1,
                'output': '',
                'error': f'æ‰§è¡Œé”™è¯¯: {str(e)}'
            }
    
    def _print_results(self):
        """æ‰“å°æµ‹è¯•ç»“æœ"""
        print("\n" + "="*60)
        print(f"ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("="*60)
        
        print(f"ğŸ·ï¸  å¥—ä»¶åç§°: {self.results['suite_name']}")
        print(f"â±ï¸  æ‰§è¡Œæ—¶é—´: {self.results['execution_time']:.2f}ç§’")
        print(f"ğŸ“ˆ é¢„æœŸæ—¶é—´: {self.results['expected_time']}ç§’")
        
        if self.results['success']:
            print("âœ… æµ‹è¯•çŠ¶æ€: é€šè¿‡")
            performance_ratio = self.results['execution_time'] / self.results['expected_time']
            if performance_ratio < 0.8:
                print("ğŸš€ æ€§èƒ½: è¶…é¢„æœŸ (æ¯”é¢„æœŸå¿«)")
            elif performance_ratio > 1.2:
                print("ğŸŒ æ€§èƒ½: ä½äºé¢„æœŸ (æ¯”é¢„æœŸæ…¢)")
            else:
                print("âš¡ æ€§èƒ½: ç¬¦åˆé¢„æœŸ")
        else:
            print("âŒ æµ‹è¯•çŠ¶æ€: å¤±è´¥")
        
        # è§£ææµ‹è¯•è¾“å‡ºä¸­çš„ç»Ÿè®¡ä¿¡æ¯
        if self.results['output']:
            self._parse_test_statistics(self.results['output'])
    
    def _parse_test_statistics(self, output: str):
        """è§£ææµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
        lines = output.split('\n')
        
        for line in lines:
            if 'passed' in line and ('failed' in line or 'error' in line):
                print(f"ğŸ“ˆ è¯¦ç»†ç»“æœ: {line.strip()}")
                break
            elif 'passed' in line and 'warning' in line:
                print(f"ğŸ“ˆ è¯¦ç»†ç»“æœ: {line.strip()}")
                break
    
    def run_custom_suite(self, name: str, paths: List[str], **kwargs) -> Dict:
        """è¿è¡Œè‡ªå®šä¹‰æµ‹è¯•å¥—ä»¶"""
        return self.run_tests(custom_paths=paths, **kwargs)
    
    def run_by_tag(self, tag: str, **kwargs) -> Dict:
        """æŒ‰æ ‡ç­¾è¿è¡Œæµ‹è¯•"""
        custom_paths = [f"tests/ -m {tag}"]
        return self.run_tests(custom_paths=custom_paths, **kwargs)
    
    def run_changed_tests(self, **kwargs) -> Dict:
        """è¿è¡Œå˜æ›´ç›¸å…³çš„æµ‹è¯•"""
        # è¿™é‡Œå¯ä»¥é›†æˆgit diffæ¥æ‰¾åˆ°å˜æ›´çš„æ–‡ä»¶
        # ç„¶åè¿è¡Œç›¸å…³çš„æµ‹è¯•
        print("ğŸ” æ£€æµ‹ä»£ç å˜æ›´...")
        # ç®€åŒ–å®ç°ï¼Œè¿è¡Œå¿«é€Ÿæµ‹è¯•
        return self.run_tests(level=TestLevel.FAST, **kwargs)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description="ä¼˜åŒ–çš„æµ‹è¯•è¿è¡Œå™¨")
    
    parser.add_argument(
        '--level', '-l',
        choices=['smoke', 'fast', 'full', 'frontend', 'regression', 'performance'],
        default='fast',
        help='æµ‹è¯•çº§åˆ« (é»˜è®¤: fast)'
    )
    
    parser.add_argument(
        '--parallel', '-p',
        action='store_true',
        help='å¯ç”¨å¹¶è¡Œæ‰§è¡Œ'
    )
    
    parser.add_argument(
        '--coverage', '-c',
        action='store_true',
        help='ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š'
    )
    
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        default=True,
        help='è¯¦ç»†è¾“å‡º'
    )
    
    parser.add_argument(
        '--fail-fast', '-x',
        action='store_true',
        help='é‡åˆ°å¤±è´¥ç«‹å³åœæ­¢'
    )
    
    parser.add_argument(
        '--paths',
        nargs='+',
        help='è‡ªå®šä¹‰æµ‹è¯•è·¯å¾„'
    )
    
    parser.add_argument(
        '--tag', '-t',
        help='æŒ‰æ ‡ç­¾è¿è¡Œæµ‹è¯•'
    )
    
    parser.add_argument(
        '--changed',
        action='store_true',
        help='åªè¿è¡Œå˜æ›´ç›¸å…³çš„æµ‹è¯•'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºæµ‹è¯•è¿è¡Œå™¨
    runner = TestRunner()
    
    # æ ¹æ®å‚æ•°æ‰§è¡Œæµ‹è¯•
    if args.changed:
        result = runner.run_changed_tests(
            parallel=args.parallel,
            coverage=args.coverage,
            verbose=args.verbose,
            fail_fast=args.fail_fast
        )
    elif args.tag:
        result = runner.run_by_tag(
            args.tag,
            parallel=args.parallel,
            coverage=args.coverage,
            verbose=args.verbose,
            fail_fast=args.fail_fast
        )
    elif args.paths:
        result = runner.run_custom_suite(
            "è‡ªå®šä¹‰æµ‹è¯•",
            args.paths,
            parallel=args.parallel,
            coverage=args.coverage,
            verbose=args.verbose,
            fail_fast=args.fail_fast
        )
    else:
        level = TestLevel(args.level)
        result = runner.run_tests(
            level=level,
            parallel=args.parallel,
            coverage=args.coverage,
            verbose=args.verbose,
            fail_fast=args.fail_fast
        )
    
    # è¿”å›é€‚å½“çš„é€€å‡ºç 
    sys.exit(0 if result['success'] else 1)


if __name__ == '__main__':
    main()


# ä½¿ç”¨ç¤ºä¾‹:
"""
# å¿«é€Ÿæµ‹è¯•ï¼ˆé»˜è®¤ï¼‰
python tests/test_runner_optimized.py

# å†’çƒŸæµ‹è¯•
python tests/test_runner_optimized.py --level smoke

# å¹¶è¡Œæ‰§è¡Œå®Œæ•´æµ‹è¯•
python tests/test_runner_optimized.py --level full --parallel

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
python tests/test_runner_optimized.py --coverage

# è¿è¡Œç‰¹å®šè·¯å¾„çš„æµ‹è¯•
python tests/test_runner_optimized.py --paths tests/unit/test_links_module.py

# æŒ‰æ ‡ç­¾è¿è¡Œæµ‹è¯•
python tests/test_runner_optimized.py --tag unit

# åªè¿è¡Œå˜æ›´ç›¸å…³çš„æµ‹è¯•
python tests/test_runner_optimized.py --changed
"""

print("âœ… ä¼˜åŒ–çš„æµ‹è¯•è¿è¡Œå™¨åˆ›å»ºå®Œæˆ")