# AI助手模块 - 功能设计

## 1. 模块概述

### 1.1 模块定位
AI助手模块是Alpha平台的核心智能功能模块，为用户提供智能对话、知识问答、内容生成、学习辅助等AI服务。

### 1.2 核心价值
- **智能对话**: 提供自然语言交互体验
- **知识问答**: 基于用户数据提供精准答案
- **内容生成**: 辅助用户创建高质量内容
- **学习辅助**: 个性化学习建议和指导
- **工作助手**: 提升工作效率和决策质量

### 1.3 功能架构
```
AI助手模块
├── 对话管理
│   ├── 实时对话
│   ├── 对话历史
│   ├── 对话分类
│   └── 对话导出
├── 模型管理
│   ├── 模型导入
│   ├── 模型配置
│   ├── 模型切换
│   └── 性能监控
├── 知识库
│   ├── 文档导入
│   ├── 知识检索
│   ├── 知识更新
│   └── 知识分析
├── 智能推荐
│   ├── 内容推荐
│   ├── 学习建议
│   ├── 工作提醒
│   └── 个性化推荐
└── 系统管理
    ├── 权限控制
    ├── 使用统计
    ├── 成本控制
    └── 安全审计
```

## 2. 核心功能设计

### 2.1 智能对话系统

#### 2.1.1 实时对话
- **多轮对话**: 支持上下文理解和连续对话
- **多模态输入**: 支持文本、语音、图片输入
- **实时响应**: 流式输出，提升用户体验
- **对话记忆**: 记住对话历史和用户偏好

#### 2.1.2 对话管理
- **对话分类**: 按主题、时间、重要性分类
- **对话搜索**: 全文搜索对话内容
- **对话导出**: 支持多种格式导出
- **对话分享**: 安全分享对话内容

#### 2.1.3 对话模板
- **预设模板**: 常用对话场景模板
- **自定义模板**: 用户自定义对话模板
- **模板管理**: 模板的增删改查
- **模板推荐**: 智能推荐相关模板

### 2.2 模型管理系统

#### 2.2.1 模型导入
- **本地模型**: 支持本地部署的模型
- **云端模型**: 集成云端AI服务
- **模型格式**: 支持多种模型格式
- **模型验证**: 模型兼容性检查

#### 2.2.2 模型配置
- **参数调优**: 模型参数配置
- **性能设置**: 响应速度和质量平衡
- **成本控制**: API调用成本管理
- **安全设置**: 模型访问权限控制

#### 2.2.3 模型切换
- **动态切换**: 运行时切换模型
- **智能选择**: 根据任务自动选择模型
- **负载均衡**: 多模型负载分配
- **故障转移**: 模型故障自动切换

### 2.3 知识库系统

#### 2.3.1 文档导入
- **多格式支持**: PDF、Word、Markdown等
- **批量导入**: 支持批量文档导入
- **自动解析**: 智能解析文档结构
- **内容提取**: 提取关键信息和知识点

#### 2.3.2 知识检索
- **语义搜索**: 基于语义的智能搜索
- **向量检索**: 高维向量相似度检索
- **混合检索**: 关键词+语义混合检索
- **实时更新**: 知识库实时更新

#### 2.3.3 知识管理
- **知识分类**: 按领域、类型分类
- **知识标签**: 智能标签和手动标签
- **知识关联**: 知识点之间的关联关系
- **知识图谱**: 构建知识图谱

### 2.4 智能推荐系统

#### 2.4.1 内容推荐
- **个性化推荐**: 基于用户兴趣推荐
- **协同过滤**: 基于相似用户推荐
- **内容分析**: 分析内容质量和相关性
- **推荐解释**: 提供推荐理由

#### 2.4.2 学习建议
- **学习路径**: 个性化学习路径规划
- **知识点推荐**: 基于学习进度推荐
- **练习建议**: 智能练习题目推荐
- **复习提醒**: 基于遗忘曲线提醒

#### 2.4.3 工作助手
- **任务建议**: 智能任务分解和建议
- **时间管理**: 基于工作习惯的时间建议
- **决策支持**: 提供决策参考信息
- **效率优化**: 工作流程优化建议

## 3. 技术实现

### 3.1 数据库设计

#### 3.1.1 对话相关表
```sql
-- 对话会话表
CREATE TABLE ai_conversations (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    title VARCHAR(200),
    model_id BIGINT,
    status ENUM('active', 'archived', 'deleted') DEFAULT 'active',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (model_id) REFERENCES ai_models(id)
);

-- 对话消息表
CREATE TABLE ai_messages (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    conversation_id BIGINT NOT NULL,
    role ENUM('user', 'assistant', 'system') NOT NULL,
    content TEXT NOT NULL,
    message_type ENUM('text', 'image', 'file') DEFAULT 'text',
    tokens_used INT DEFAULT 0,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES ai_conversations(id)
);

-- 对话标签表
CREATE TABLE ai_conversation_tags (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    conversation_id BIGINT NOT NULL,
    tag_name VARCHAR(50) NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES ai_conversations(id)
);
```

#### 3.1.2 模型管理表
```sql
-- AI模型表
CREATE TABLE ai_models (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(100) NOT NULL,
    model_type ENUM('local', 'cloud', 'hybrid') NOT NULL,
    provider VARCHAR(50),
    model_config JSON,
    status ENUM('active', 'inactive', 'maintenance') DEFAULT 'active',
    cost_per_token DECIMAL(10,6),
    max_tokens INT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP
);

-- 模型使用记录表
CREATE TABLE ai_model_usage (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    model_id BIGINT NOT NULL,
    tokens_used INT NOT NULL,
    cost DECIMAL(10,6),
    request_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    response_time INT, -- 毫秒
    success BOOLEAN DEFAULT TRUE,
    error_message TEXT,
    FOREIGN KEY (user_id) REFERENCES users(id),
    FOREIGN KEY (model_id) REFERENCES ai_models(id)
);
```

#### 3.1.3 知识库表
```sql
-- 知识文档表
CREATE TABLE ai_knowledge_docs (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    title VARCHAR(200) NOT NULL,
    content TEXT,
    file_path VARCHAR(500),
    file_type VARCHAR(20),
    file_size BIGINT,
    embedding_vector JSON,
    status ENUM('processing', 'active', 'archived') DEFAULT 'processing',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    FOREIGN KEY (user_id) REFERENCES users(id)
);

-- 知识检索记录表
CREATE TABLE ai_knowledge_searches (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    user_id BIGINT NOT NULL,
    query TEXT NOT NULL,
    results JSON,
    search_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    response_time INT,
    FOREIGN KEY (user_id) REFERENCES users(id)
);
```

### 3.2 API设计

#### 3.2.1 对话管理API
```python
# 对话管理
GET    /api/v1/ai/conversations/              # 获取对话列表
POST   /api/v1/ai/conversations/              # 创建新对话
GET    /api/v1/ai/conversations/{id}/         # 获取对话详情
PUT    /api/v1/ai/conversations/{id}/         # 更新对话
DELETE /api/v1/ai/conversations/{id}/         # 删除对话

# 消息管理
GET    /api/v1/ai/conversations/{id}/messages/     # 获取对话消息
POST   /api/v1/ai/conversations/{id}/messages/     # 发送消息
PUT    /api/v1/ai/messages/{id}/                   # 更新消息
DELETE /api/v1/ai/messages/{id}/                   # 删除消息

# 对话操作
POST   /api/v1/ai/conversations/{id}/export/       # 导出对话
POST   /api/v1/ai/conversations/{id}/share/        # 分享对话
POST   /api/v1/ai/conversations/{id}/archive/      # 归档对话
```

#### 3.2.2 模型管理API
```python
# 模型管理
GET    /api/v1/ai/models/                    # 获取模型列表
POST   /api/v1/ai/models/                    # 添加模型
GET    /api/v1/ai/models/{id}/               # 获取模型详情
PUT    /api/v1/ai/models/{id}/               # 更新模型配置
DELETE /api/v1/ai/models/{id}/               # 删除模型

# 模型操作
POST   /api/v1/ai/models/{id}/test/          # 测试模型
POST   /api/v1/ai/models/{id}/switch/        # 切换模型
GET    /api/v1/ai/models/{id}/usage/         # 获取使用统计
POST   /api/v1/ai/models/{id}/config/        # 更新配置
```

#### 3.2.3 知识库API
```python
# 知识库管理
GET    /api/v1/ai/knowledge/                 # 获取知识库列表
POST   /api/v1/ai/knowledge/                 # 上传文档
GET    /api/v1/ai/knowledge/{id}/            # 获取文档详情
PUT    /api/v1/ai/knowledge/{id}/            # 更新文档
DELETE /api/v1/ai/knowledge/{id}/            # 删除文档

# 知识检索
POST   /api/v1/ai/knowledge/search/          # 搜索知识
GET    /api/v1/ai/knowledge/suggest/         # 搜索建议
POST   /api/v1/ai/knowledge/query/           # 知识问答
```

### 3.3 前端组件

#### 3.3.1 对话组件
```vue
<template>
  <div class="ai-chat-container">
    <!-- 对话列表 -->
    <div class="conversation-list">
      <ConversationList 
        :conversations="conversations"
        @select="selectConversation"
        @create="createConversation"
      />
    </div>
    
    <!-- 对话界面 -->
    <div class="chat-interface">
      <ChatHeader 
        :conversation="currentConversation"
        @export="exportConversation"
        @share="shareConversation"
      />
      
      <ChatMessages 
        :messages="messages"
        @edit="editMessage"
        @delete="deleteMessage"
      />
      
      <ChatInput 
        v-model="inputMessage"
        @send="sendMessage"
        @upload="uploadFile"
      />
    </div>
    
    <!-- 侧边栏 -->
    <div class="chat-sidebar">
      <ModelSelector 
        :models="models"
        :current-model="currentModel"
        @change="changeModel"
      />
      
      <KnowledgePanel 
        :knowledge="knowledge"
        @search="searchKnowledge"
      />
    </div>
  </div>
</template>

<script>
import { ref, reactive, onMounted } from 'vue'
import { useAIChat } from '@/stores/ai-chat'
import ConversationList from './ConversationList.vue'
import ChatHeader from './ChatHeader.vue'
import ChatMessages from './ChatMessages.vue'
import ChatInput from './ChatInput.vue'
import ModelSelector from './ModelSelector.vue'
import KnowledgePanel from './KnowledgePanel.vue'

export default {
  name: 'AIChat',
  components: {
    ConversationList,
    ChatHeader,
    ChatMessages,
    ChatInput,
    ModelSelector,
    KnowledgePanel
  },
  setup() {
    const aiChatStore = useAIChat()
    const inputMessage = ref('')
    const currentConversation = ref(null)
    const currentModel = ref(null)
    
    const selectConversation = async (conversation) => {
      currentConversation.value = conversation
      await aiChatStore.loadMessages(conversation.id)
    }
    
    const sendMessage = async () => {
      if (!inputMessage.value.trim()) return
      
      await aiChatStore.sendMessage({
        conversationId: currentConversation.value.id,
        content: inputMessage.value,
        modelId: currentModel.value?.id
      })
      
      inputMessage.value = ''
    }
    
    const changeModel = (model) => {
      currentModel.value = model
    }
    
    onMounted(async () => {
      await aiChatStore.loadConversations()
      await aiChatStore.loadModels()
    })
    
    return {
      inputMessage,
      currentConversation,
      currentModel,
      conversations: aiChatStore.conversations,
      messages: aiChatStore.messages,
      models: aiChatStore.models,
      knowledge: aiChatStore.knowledge,
      selectConversation,
      sendMessage,
      changeModel
    }
  }
}
</script>
```

#### 3.3.2 模型管理组件
```vue
<template>
  <div class="model-management">
    <div class="model-header">
      <h2>AI模型管理</h2>
      <el-button type="primary" @click="showAddModel">
        添加模型
      </el-button>
    </div>
    
    <div class="model-list">
      <el-table :data="models" style="width: 100%">
        <el-table-column prop="name" label="模型名称" />
        <el-table-column prop="model_type" label="类型" />
        <el-table-column prop="provider" label="提供商" />
        <el-table-column prop="status" label="状态">
          <template #default="scope">
            <el-tag :type="getStatusType(scope.row.status)">
              {{ scope.row.status }}
            </el-tag>
          </template>
        </el-table-column>
        <el-table-column label="操作">
          <template #default="scope">
            <el-button size="small" @click="editModel(scope.row)">
              编辑
            </el-button>
            <el-button size="small" @click="testModel(scope.row)">
              测试
            </el-button>
            <el-button size="small" type="danger" @click="deleteModel(scope.row)">
              删除
            </el-button>
          </template>
        </el-table-column>
      </el-table>
    </div>
    
    <!-- 添加/编辑模型对话框 -->
    <ModelDialog 
      v-model="showDialog"
      :model="editingModel"
      @save="saveModel"
    />
  </div>
</template>

<script>
import { ref, reactive, onMounted } from 'vue'
import { useAIModels } from '@/stores/ai-models'
import ModelDialog from './ModelDialog.vue'

export default {
  name: 'ModelManagement',
  components: { ModelDialog },
  setup() {
    const aiModelsStore = useAIModels()
    const showDialog = ref(false)
    const editingModel = ref(null)
    
    const showAddModel = () => {
      editingModel.value = null
      showDialog.value = true
    }
    
    const editModel = (model) => {
      editingModel.value = { ...model }
      showDialog.value = true
    }
    
    const saveModel = async (modelData) => {
      if (editingModel.value) {
        await aiModelsStore.updateModel(editingModel.value.id, modelData)
      } else {
        await aiModelsStore.addModel(modelData)
      }
      showDialog.value = false
    }
    
    const testModel = async (model) => {
      await aiModelsStore.testModel(model.id)
    }
    
    const deleteModel = async (model) => {
      await aiModelsStore.deleteModel(model.id)
    }
    
    onMounted(async () => {
      await aiModelsStore.loadModels()
    })
    
    return {
      models: aiModelsStore.models,
      showDialog,
      editingModel,
      showAddModel,
      editModel,
      saveModel,
      testModel,
      deleteModel
    }
  }
}
</script>
```

### 3.4 后端服务

#### 3.4.1 AI服务类
```python
from typing import List, Dict, Any
import asyncio
import aiohttp
from transformers import pipeline
import torch

class AIService:
    def __init__(self):
        self.models = {}
        self.conversation_history = {}
        
    async def initialize_models(self):
        """初始化AI模型"""
        # 加载本地模型
        self.models['local'] = {
            'text_generation': pipeline('text-generation', model='gpt2'),
            'text_classification': pipeline('text-classification'),
            'question_answering': pipeline('question-answering')
        }
        
    async def generate_response(self, 
                              conversation_id: str, 
                              message: str, 
                              model_config: Dict[str, Any]) -> str:
        """生成AI响应"""
        try:
            # 获取对话历史
            history = self.conversation_history.get(conversation_id, [])
            
            # 构建上下文
            context = self._build_context(history, message)
            
            # 选择模型
            model = self._select_model(model_config)
            
            # 生成响应
            response = await self._generate_with_model(model, context, model_config)
            
            # 更新对话历史
            self._update_conversation_history(conversation_id, message, response)
            
            return response
            
        except Exception as e:
            logger.error(f"生成响应失败: {e}")
            return "抱歉，我遇到了一些问题，请稍后再试。"
    
    def _build_context(self, history: List[Dict], message: str) -> str:
        """构建对话上下文"""
        context = ""
        for msg in history[-10:]:  # 保留最近10条消息
            if msg['role'] == 'user':
                context += f"用户: {msg['content']}\n"
            else:
                context += f"助手: {msg['content']}\n"
        context += f"用户: {message}\n助手:"
        return context
    
    def _select_model(self, config: Dict[str, Any]):
        """选择AI模型"""
        model_type = config.get('model_type', 'local')
        task_type = config.get('task_type', 'text_generation')
        
        if model_type == 'local':
            return self.models['local'].get(task_type)
        else:
            return self._get_cloud_model(config)
    
    async def _generate_with_model(self, model, context: str, config: Dict[str, Any]) -> str:
        """使用模型生成响应"""
        if hasattr(model, 'generate'):
            # 本地模型
            inputs = model.tokenizer(context, return_tensors="pt")
            outputs = model.generate(
                inputs.input_ids,
                max_length=config.get('max_length', 100),
                temperature=config.get('temperature', 0.7),
                do_sample=True
            )
            response = model.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return response.split('助手:')[-1].strip()
        else:
            # 云端模型
            return await self._call_cloud_api(model, context, config)
    
    async def _call_cloud_api(self, api_config: Dict, context: str, config: Dict[str, Any]) -> str:
        """调用云端API"""
        async with aiohttp.ClientSession() as session:
            async with session.post(
                api_config['url'],
                headers=api_config['headers'],
                json={
                    'prompt': context,
                    'max_tokens': config.get('max_length', 100),
                    'temperature': config.get('temperature', 0.7)
                }
            ) as response:
                result = await response.json()
                return result.get('choices', [{}])[0].get('text', '')
    
    def _update_conversation_history(self, conversation_id: str, message: str, response: str):
        """更新对话历史"""
        if conversation_id not in self.conversation_history:
            self.conversation_history[conversation_id] = []
        
        self.conversation_history[conversation_id].extend([
            {'role': 'user', 'content': message},
            {'role': 'assistant', 'content': response}
        ])
        
        # 限制历史记录长度
        if len(self.conversation_history[conversation_id]) > 50:
            self.conversation_history[conversation_id] = self.conversation_history[conversation_id][-50:]
```

#### 3.4.2 知识库服务类
```python
import chromadb
from sentence_transformers import SentenceTransformer
import numpy as np
from typing import List, Dict, Any

class KnowledgeService:
    def __init__(self):
        self.embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
        self.chroma_client = chromadb.Client()
        self.collections = {}
        
    def create_collection(self, collection_name: str):
        """创建知识库集合"""
        if collection_name not in self.collections:
            collection = self.chroma_client.create_collection(
                name=collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            self.collections[collection_name] = collection
        return self.collections[collection_name]
    
    def add_document(self, collection_name: str, document: Dict[str, Any]):
        """添加文档到知识库"""
        collection = self.create_collection(collection_name)
        
        # 分割文档
        chunks = self._split_document(document['content'])
        
        # 生成嵌入向量
        embeddings = self.embedding_model.encode(chunks)
        
        # 添加到集合
        collection.add(
            documents=chunks,
            embeddings=embeddings.tolist(),
            metadatas=[{
                'title': document['title'],
                'source': document.get('source', ''),
                'chunk_index': i
            } for i in range(len(chunks))],
            ids=[f"{document['id']}_{i}" for i in range(len(chunks))]
        )
        
        return len(chunks)
    
    def search_knowledge(self, collection_name: str, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """搜索知识库"""
        if collection_name not in self.collections:
            return []
        
        collection = self.collections[collection_name]
        
        # 生成查询向量
        query_embedding = self.embedding_model.encode([query])
        
        # 搜索相似文档
        results = collection.query(
            query_embeddings=query_embedding.tolist(),
            n_results=top_k
        )
        
        # 格式化结果
        formatted_results = []
        for i in range(len(results['documents'][0])):
            formatted_results.append({
                'content': results['documents'][0][i],
                'metadata': results['metadatas'][0][i],
                'distance': results['distances'][0][i]
            })
        
        return formatted_results
    
    def _split_document(self, content: str, chunk_size: int = 1000) -> List[str]:
        """分割文档"""
        words = content.split()
        chunks = []
        current_chunk = []
        current_size = 0
        
        for word in words:
            if current_size + len(word) > chunk_size and current_chunk:
                chunks.append(' '.join(current_chunk))
                current_chunk = [word]
                current_size = len(word)
            else:
                current_chunk.append(word)
                current_size += len(word) + 1
        
        if current_chunk:
            chunks.append(' '.join(current_chunk))
        
        return chunks
    
    def delete_document(self, collection_name: str, document_id: str):
        """删除文档"""
        if collection_name in self.collections:
            collection = self.collections[collection_name]
            # 删除所有相关的chunk
            collection.delete(where={"document_id": document_id})
    
    def get_collection_stats(self, collection_name: str) -> Dict[str, Any]:
        """获取集合统计信息"""
        if collection_name not in self.collections:
            return {}
        
        collection = self.collections[collection_name]
        count = collection.count()
        
        return {
            'name': collection_name,
            'document_count': count,
            'created_at': collection.metadata.get('created_at', ''),
            'last_updated': collection.metadata.get('last_updated', '')
        }
```

## 4. 性能优化

### 4.1 响应速度优化
1. **模型缓存**: 缓存常用模型到内存
2. **异步处理**: 使用异步处理提升并发性能
3. **流式输出**: 实现流式响应减少等待时间
4. **连接池**: 使用连接池管理API连接

### 4.2 成本控制
1. **Token计数**: 精确统计token使用量
2. **模型选择**: 根据任务复杂度选择合适模型
3. **缓存策略**: 缓存常见问题答案
4. **批量处理**: 批量处理减少API调用次数

### 4.3 安全控制
1. **输入验证**: 严格验证用户输入
2. **内容过滤**: 过滤不当内容
3. **权限控制**: 细粒度权限管理
4. **审计日志**: 记录所有操作日志

## 5. 监控和运维

### 5.1 性能监控
- **响应时间**: 监控API响应时间
- **成功率**: 监控请求成功率
- **资源使用**: 监控CPU、内存使用
- **错误率**: 监控错误发生频率

### 5.2 成本监控
- **Token使用量**: 统计token消耗
- **API调用次数**: 监控API调用频率
- **成本趋势**: 分析成本变化趋势
- **异常告警**: 成本异常自动告警

### 5.3 质量监控
- **用户满意度**: 收集用户反馈
- **对话质量**: 评估对话质量
- **知识准确性**: 验证知识库准确性
- **模型性能**: 评估模型效果

