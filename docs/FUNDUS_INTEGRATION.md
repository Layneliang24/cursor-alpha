# Fundusçˆ¬è™«é›†æˆè¯´æ˜

## ğŸ“‹ æ¦‚è¿°

æœ¬é¡¹ç›®å·²æˆåŠŸé›†æˆFundusçˆ¬è™«æ¡†æ¶ï¼Œç”¨äºæå‡è‹±è¯­æ–°é—»çˆ¬å–çš„æ•°æ®è´¨é‡ã€‚Fundusæ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºæ–°é—»ç½‘ç«™è®¾è®¡çš„Pythonçˆ¬è™«æ¡†æ¶ï¼Œå…·æœ‰ä»¥ä¸‹ä¼˜åŠ¿ï¼š

- **ä¸“é—¨ä¸ºæ–°é—»è®¾è®¡**ï¼šå†…ç½®æ–°é—»æ–‡ç« è§£æå™¨
- **é«˜è´¨é‡æ•°æ®**ï¼šè‡ªåŠ¨æå–æ ‡é¢˜ã€æ­£æ–‡ã€ä½œè€…ã€å‘å¸ƒæ—¶é—´
- **å¤šè¯­è¨€æ”¯æŒ**ï¼šæ”¯æŒå¤šç§è‹±è¯­æ–°é—»æº
- **ç¨³å®šæ€§å¼º**ï¼šå†…ç½®é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- **æ‰©å±•æ€§å¥½**ï¼šæ”¯æŒè‡ªå®šä¹‰è§£æè§„åˆ™

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd backend
pip install fundus
```

### 2. åŸºæœ¬ä½¿ç”¨

```bash
# ä½¿ç”¨Fundusçˆ¬è™«æŠ“å–BBCæ–°é—»
python manage.py crawl_news --source bbc --crawler fundus

# æŠ“å–æ‰€æœ‰æ”¯æŒçš„æ–°é—»æº
python manage.py crawl_news --source all --crawler fundus

# æµ‹è¯•æ¨¡å¼ï¼ˆä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
python manage.py crawl_news --source bbc --crawler fundus --dry-run --verbose
```

### 3. æ”¯æŒçš„æ–°é—»æº

#### Fundusçˆ¬è™«æ”¯æŒçš„æ–°é—»æºï¼š
- **BBC** (`bbc`)
- **CNN** (`cnn`)
- **Reuters** (`reuters`)
- **TechCrunch** (`techcrunch`)
- **The Guardian** (`the_guardian`)
- **The New York Times** (`the_new_york_times`)
- **Wired** (`wired`)
- **Ars Technica** (`ars_technica`)
- **Hacker News** (`hacker_news`)
- **Stack Overflow Blog** (`stack_overflow`)

#### ä¼ ç»Ÿçˆ¬è™«æ”¯æŒçš„æ–°é—»æºï¼š
- **BBC** (`bbc`)
- **CNN** (`cnn`)
- **Reuters** (`reuters`)
- **TechCrunch** (`techcrunch`)
- **China Daily** (`local_test`)
- **æ–°åç¤¾è‹±è¯­** (`xinhua`)

## ğŸ”§ æŠ€æœ¯å®ç°

### 1. æ ¸å¿ƒç»„ä»¶

#### FundusCrawlerService
```python
from apps.english.fundus_crawler import FundusCrawlerService

# åˆ›å»ºæœåŠ¡å®ä¾‹
service = FundusCrawlerService()

# è·å–å¯ç”¨å‘å¸ƒè€…
available = service.get_available_publishers()

# çˆ¬å–æŒ‡å®šå‘å¸ƒè€…
articles = service.crawl_publisher('bbc', max_articles=10)

# çˆ¬å–æ‰€æœ‰æ”¯æŒçš„å‘å¸ƒè€…
all_articles = service.crawl_all_supported(max_articles_per_publisher=5)
```

#### FundusNewsItem
```python
from apps.english.fundus_crawler import FundusNewsItem

# åˆ›å»ºæ–°é—»é¡¹
item = FundusNewsItem(
    title="Article Title",
    content="Article content...",
    url="https://example.com/article",
    source="BBC",
    published_at=datetime.now(),
    summary="Article summary",
    difficulty_level="intermediate",
    tags=["news", "technology"],
    image_url="https://example.com/image.jpg",
    image_alt="Image description"
)
```

### 2. æ•°æ®è´¨é‡ä¿è¯

#### å†…å®¹è¿‡æ»¤
- è‡ªåŠ¨è¿‡æ»¤å†…å®¹è¿‡çŸ­çš„æ–‡ç« ï¼ˆå°‘äº50ä¸ªå•è¯ï¼‰
- æ™ºèƒ½å»é‡ï¼ˆåŸºäºURLï¼‰
- å†…å®¹è´¨é‡è¯„ä¼°

#### éš¾åº¦åˆ†çº§
- **beginner**: ç®€å•è¯æ±‡ï¼ŒçŸ­å¥å­ï¼Œé€‚åˆåˆå­¦è€…
- **intermediate**: ä¸­ç­‰éš¾åº¦ï¼Œé€‚åˆä¸­çº§å­¦ä¹ è€…
- **advanced**: å¤æ‚è¯æ±‡ï¼Œé•¿å¥å­ï¼Œé€‚åˆé«˜çº§å­¦ä¹ è€…

#### æ ‡ç­¾æå–
è‡ªåŠ¨ä»å†…å®¹ä¸­æå–ç›¸å…³æ ‡ç­¾ï¼š
- æŠ€æœ¯ç±»ï¼štechnology, tech, ai, software
- å•†ä¸šç±»ï¼šbusiness, economy, finance
- å¥åº·ç±»ï¼šhealth, medical, healthcare
- ç§‘å­¦ç±»ï¼šscience, research, study
- æ”¿æ²»ç±»ï¼špolitics, government, policy
- ç¯å¢ƒç±»ï¼šenvironment, climate, energy
- å›½é™…ç±»ï¼šworld, international, global

### 3. é”™è¯¯å¤„ç†

- ç½‘ç»œè¿æ¥å¼‚å¸¸å¤„ç†
- å†…å®¹è§£æå¤±è´¥å¤„ç†
- å‘å¸ƒè€…ä¸å¯ç”¨æ—¶çš„é™çº§å¤„ç†
- è¯¦ç»†çš„æ—¥å¿—è®°å½•

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–

### 1. å»¶è¿Ÿåˆå§‹åŒ–
```python
# é¿å…åœ¨å¯¼å…¥æ—¶åˆå§‹åŒ–ï¼Œæé«˜å¯åŠ¨é€Ÿåº¦
fundus_crawler_service = None

def get_fundus_service():
    global fundus_crawler_service
    if fundus_crawler_service is None:
        fundus_crawler_service = FundusCrawlerService()
    return fundus_crawler_service
```

### 2. å¹¶å‘æ§åˆ¶
- æ§åˆ¶æ¯ä¸ªå‘å¸ƒè€…çš„çˆ¬å–æ•°é‡
- é¿å…å¯¹ç›®æ ‡ç½‘ç«™é€ æˆè¿‡å¤§å‹åŠ›
- æ”¯æŒè‡ªå®šä¹‰çˆ¬å–é—´éš”

### 3. ç¼“å­˜æœºåˆ¶
- é¿å…é‡å¤çˆ¬å–ç›¸åŒURL
- æ™ºèƒ½æ›´æ–°æœºåˆ¶

## ğŸ§ª æµ‹è¯•

### å•å…ƒæµ‹è¯•
```bash
# è¿è¡ŒFundusç›¸å…³æµ‹è¯•
cd tests
pytest unit/test_fundus_crawler.py -v
```

### é›†æˆæµ‹è¯•
```bash
# æµ‹è¯•Fundusçˆ¬è™«åŠŸèƒ½
python manage.py crawl_news --source bbc --crawler fundus --dry-run --verbose
```

## ğŸ”„ ä¸ç°æœ‰ç³»ç»Ÿé›†æˆ

### 1. å…¼å®¹æ€§
Fundusçˆ¬è™«å®Œå…¨å…¼å®¹ç°æœ‰çš„æ–°é—»ç³»ç»Ÿï¼š
- ä½¿ç”¨ç›¸åŒçš„æ•°æ®åº“æ¨¡å‹
- æ”¯æŒç›¸åŒçš„APIæ¥å£
- ä¿æŒç›¸åŒçš„æ•°æ®æ ¼å¼

### 2. æ··åˆæ¨¡å¼
æ”¯æŒåŒæ—¶ä½¿ç”¨ä¼ ç»Ÿçˆ¬è™«å’ŒFundusçˆ¬è™«ï¼š
```bash
# ä½¿ç”¨ä¸¤ç§çˆ¬è™«
python manage.py crawl_news --source all --crawler both
```

### 3. æ¸è¿›å¼è¿ç§»
- å¯ä»¥é€æ­¥ä»ä¼ ç»Ÿçˆ¬è™«è¿ç§»åˆ°Fundusçˆ¬è™«
- æ”¯æŒå¹¶è¡Œè¿è¡Œä¸¤ç§çˆ¬è™«
- ä¸å½±å“ç°æœ‰åŠŸèƒ½

## ğŸ“ˆ ç›‘æ§å’Œæ—¥å¿—

### 1. æ—¥å¿—è®°å½•
```python
import logging
logger = logging.getLogger(__name__)

# è®°å½•çˆ¬å–è¿›åº¦
logger.info(f"å¼€å§‹çˆ¬å– {publisher_id} çš„æ–°é—»...")
logger.info(f"{publisher_id} çˆ¬å–å®Œæˆ: {len(articles)} æ¡æ–°é—»")
```

### 2. æ€§èƒ½ç›‘æ§
- çˆ¬å–æ—¶é—´ç»Ÿè®¡
- æˆåŠŸç‡ç›‘æ§
- æ•°æ®è´¨é‡è¯„ä¼°

### 3. é”™è¯¯å‘Šè­¦
- ç½‘ç»œè¿æ¥å¤±è´¥å‘Šè­¦
- å†…å®¹è§£æå¤±è´¥å‘Šè­¦
- å‘å¸ƒè€…ä¸å¯ç”¨å‘Šè­¦

## ğŸš€ æœªæ¥è§„åˆ’

### 1. åŠŸèƒ½æ‰©å±•
- æ”¯æŒæ›´å¤šæ–°é—»æº
- å¢åŠ å†…å®¹åˆ†ç±»åŠŸèƒ½
- æ”¯æŒå¤šè¯­è¨€æ–°é—»

### 2. æ€§èƒ½ä¼˜åŒ–
- å¼‚æ­¥çˆ¬å–æ”¯æŒ
- åˆ†å¸ƒå¼çˆ¬å–
- æ™ºèƒ½è°ƒåº¦ç®—æ³•

### 3. è´¨é‡æå‡
- æ›´ç²¾ç¡®çš„éš¾åº¦è¯„ä¼°
- æ›´æ™ºèƒ½çš„æ ‡ç­¾æå–
- æ›´å¥½çš„å†…å®¹å»é‡

## ğŸ“ æ”¯æŒ

å¦‚æœ‰é—®é¢˜ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„ç›¸å…³ç« èŠ‚
2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶
3. è¿è¡Œæµ‹è¯•ç”¨ä¾‹
4. è”ç³»å¼€å‘å›¢é˜Ÿ

---

*æœ€åæ›´æ–°ï¼š2024å¹´12æœˆ*
